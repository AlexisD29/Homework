{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Project_Titanic_AlexisD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexisD29/Homework/blob/master/Project_Titanic_AlexisD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbOytv4mz_lx"
      },
      "source": [
        "# Project 1 - Titanic - AlexisD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGbgOa8z_ly"
      },
      "source": [
        "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.\n",
        "\n",
        "## 1) Upload this jupyter notebook page to your colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD05VVzIE_im"
      },
      "source": [
        "## 2) Get the Shareable link for your page and update the URL below for your Jupyter Notebook:\n",
        "- _Make sure you select __'Anyone with the Link'__ option_\n",
        "\n",
        "__This jupyter notebook page is located at__: https://colab.research.google.com/drive/1XKQwKVnLGG3KdQ1nPpUHKeCuaeGpu6ca?usp=sharing\n",
        "\n",
        "We will click on the link above to visit to your Jupyter Notebook page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYRaIawfz_l0"
      },
      "source": [
        "## 3) Downloaded the data (train.csv and test.csv files) from Kaggle and then upload them using the first code block below. \n",
        "- To download the files, login to [Kaggle](https://www.kaggle.com/) and go to the [Titanic challenge](https://www.kaggle.com/c/titanic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ucl-YDyF9yu"
      },
      "source": [
        "Keep the following code block as it is. Use it to upload the donwloaded csv files and to save them into your colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Eb5SNhz_l6",
        "outputId": "af8ef8ee-e54f-4c6b-9960-7ca56071a394",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "\n",
        "train_data_dict = files.upload() #uploads as a disctionary and creates a file\n",
        "os.remove('train.csv') #remove the file created during upload that is in the root folder\n",
        "train_data = pd.read_csv(io.StringIO(train_data_dict['train.csv'].decode('utf-8')),sep=',') #get the data from the dictionary to the dataframe\n",
        "\n",
        "test_data_dict = files.upload() #uploads as a disctionary and creates a file\n",
        "os.remove('test.csv') #remove the file created during upload that is in the root folder\n",
        "test_data = pd.read_csv(io.StringIO(test_data_dict['test.csv'].decode('utf-8')),sep=',') #get the data from the dictionary to the dataframe\n",
        "\n",
        "titanic_dir_path = os.path.join(\"datasets\", \"titanic\")\n",
        "os.makedirs(titanic_dir_path, exist_ok=True) #create the folder\n",
        "train_csv_path = os.path.join(titanic_dir_path, \"train.csv\") #create the path for the csv file \n",
        "test_csv_path = os.path.join(titanic_dir_path, \"test.csv\") #create the path for the csv file\n",
        "\n",
        "train_data.to_csv(train_csv_path, index=False) #save the data to csv file\n",
        "test_data.to_csv(test_csv_path, index=False) #save the data to csv file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-852028c1-17b2-4399-81c6-b8d5268d91a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-852028c1-17b2-4399-81c6-b8d5268d91a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c51dfc1-1555-4cb0-bfbb-01f81d4b7644\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c51dfc1-1555-4cb0-bfbb-01f81d4b7644\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r504INxDG_1"
      },
      "source": [
        "Once you upload the data, they will be saved into the `datasets/titanic` directory. After uploading, you don't need to upload them again. You can start run your code starting the below code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipoqlpnxz_l8"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "titanic_dir_path = os.path.join(\"datasets\", \"titanic\")\n",
        "train_csv_path = os.path.join(titanic_dir_path, \"train.csv\") #create the path for the csv file \n",
        "test_csv_path = os.path.join(titanic_dir_path, \"test.csv\") #create the path for the csv file\n",
        "\n",
        "train_data = pd.read_csv(train_csv_path)\n",
        "test_data = pd.read_csv(test_csv_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1KYNdEIz_l_"
      },
      "source": [
        "## 4) Answer the Questions Below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPi2qvhJGmN3"
      },
      "source": [
        "###\t4.1) Which attributes do we have and what are their meaning? List the attributes and then briefly explain. To get the description of the attributes, you can do a little research on the web. No code needed to answer this question.\n",
        "-------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrhrDIJdf2I0"
      },
      "source": [
        "The attributes we have are PassengerId,Survived,Pclass,\tName,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin, and Embarked.\n",
        "PassengerId: Idenification of passenger on the titantic\n",
        "Survived: 0 for Not Survived and 1 for Survived\n",
        "Pclass: Ticket class of passenger\n",
        "Name: The name of the passenger\n",
        "Sex: Gender of the passenger\n",
        "Age: Age of the passenger\n",
        "SibSp: # of siblings/spouses on board\n",
        "Parch:# of parents/childeren on board\n",
        "Ticket: Ticket number\n",
        "Fare: Cost to  aboard the titanic\n",
        "Cabin: Number of the cabin\n",
        "Embarked: Location where passenger boarded from"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyWmgm6aGm7_"
      },
      "source": [
        "### 4.2) Show your results and explain the insights you got by studying the data with each of the following methods on both the train and test data (Note: I am not looking for a long list of insights, 2-3 insights per method execution would be fine):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuoKLarzR88P"
      },
      "source": [
        "#### 4.2.a.\thead()\n",
        "-------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8YkAGFSc5Wh",
        "outputId": "de8e1047-c26e-4693-965e-a784abf16eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OjrKvBWc5g1"
      },
      "source": [
        "The head method will return the top n rows of the train_data.\n",
        "By default, it will show the top 5 rows of the train_data.\n",
        "It displays all of the values for those rows for each of the 12 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLpVkkl7w_9i",
        "outputId": "e0d86357-ffab-4ed6-f5a5-2ee8f1b3fa76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6wrYYnnxHOZ"
      },
      "source": [
        "The top n row of the test_data will be returned with using the head method.\n",
        "By default, it will show the top 5 rows of the test_data.\n",
        "It displays all of the values for those rows for each of the 12 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tqYP2IeR_ro"
      },
      "source": [
        "#### 4.2.b.\tinfo()\n",
        "-------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVEzGMPVc-H-",
        "outputId": "3c07da38-9459-4658-f41f-0015bd4cf152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ5tPEpTc-Rs"
      },
      "source": [
        "Give concise summary of the train_data.\n",
        "It shows which attributes have missing values.\n",
        "Age for example is missing 177 values. This applies for the train_data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr8qpL52x50r",
        "outputId": "6ec35b04-a090-4f82-ba0d-082b7e8eda9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "test_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52LoCDfRx60p"
      },
      "source": [
        "Concise summary of test_data.\n",
        "It shows which attributes have missing values.\n",
        "In the test_data case, age  is missing 86 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vha7vhw5TFVm"
      },
      "source": [
        "#### 4.2.c.\tdescribe()\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-RwCVe-dBBT",
        "outputId": "4c573c27-d57d-4b70-f4d1-258f6a7bb3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV3CnKoYdBLO"
      },
      "source": [
        "The output represent the statisical details of the train_data. Also, NaN values are excluded from the stastical summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qob-UMHpBkj3",
        "outputId": "b3da79ea-f56f-4fd1-a786-5300081822aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "test_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>418.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>332.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>417.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1100.500000</td>\n",
              "      <td>2.265550</td>\n",
              "      <td>30.272590</td>\n",
              "      <td>0.447368</td>\n",
              "      <td>0.392344</td>\n",
              "      <td>35.627188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>120.810458</td>\n",
              "      <td>0.841838</td>\n",
              "      <td>14.181209</td>\n",
              "      <td>0.896760</td>\n",
              "      <td>0.981429</td>\n",
              "      <td>55.907576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>892.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>996.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1100.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1204.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1309.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
              "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
              "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
              "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
              "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
              "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
              "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
              "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
              "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djg3Y53ZBo1Z"
      },
      "source": [
        "Summary statiscal details of the test_data is represented by the output above. The standard deviation is helpful to see how much of the data from each attribute deviates from its data. For example, the standard deviation of the Fare is wide spread fairly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h2Jh7C9dI3U"
      },
      "source": [
        "#### 4.2.d.\tvalue_counts()\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP5y42dhdCDW",
        "outputId": "76b104c9-1f4e-46e7-930f-4cc5345fdf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "train_data.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId  Survived  Pclass  Name                                                  Sex     Age   SibSp  Parch  Ticket    Fare      Cabin  Embarked\n",
              "890          1         1       Behr, Mr. Karl Howell                                 male    26.0  0      0      111369    30.0000   C148   C           1\n",
              "337          0         1       Pears, Mr. Thomas Clinton                             male    29.0  1      0      113776    66.6000   C2     S           1\n",
              "332          0         1       Partner, Mr. Austen                                   male    45.5  0      0      113043    28.5000   C124   S           1\n",
              "330          1         1       Hippach, Miss. Jean Gertrude                          female  16.0  0      1      111361    57.9792   B18    C           1\n",
              "328          1         2       Ball, Mrs. (Ada E Hall)                               female  36.0  0      0      28551     13.0000   D      S           1\n",
              "                                                                                                                                                       ..\n",
              "584          0         1       Ross, Mr. John Hugo                                   male    36.0  0      0      13049     40.1250   A10    C           1\n",
              "582          1         1       Thayer, Mrs. John Borland (Marian Longstreth Morris)  female  39.0  1      1      17421     110.8833  C68    C           1\n",
              "578          1         1       Silvey, Mrs. William Baird (Alice Munger)             female  39.0  1      0      13507     55.9000   E44    S           1\n",
              "573          1         1       Flynn, Mr. John Irwin (\"Irving\")                      male    36.0  0      0      PC 17474  26.3875   E25    S           1\n",
              "2            1         1       Cumings, Mrs. John Bradley (Florence Briggs Thayer)   female  38.0  1      0      PC 17599  71.2833   C85    C           1\n",
              "Length: 183, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw9vd4VndCLh"
      },
      "source": [
        "The value_counts of train_data return the unique values and counts from the columns.\n",
        "It sorts these unique values in descending order by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq6txjgLBvOz",
        "outputId": "010416a8-38b2-4580-fcde-331a8beb4baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test_data.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId  Pclass  Name                                                 Sex     Age   SibSp  Parch  Ticket    Fare      Cabin            Embarked\n",
              "1306         1       Oliva y Ocana, Dona. Fermina                         female  39.0  0      0      PC 17758  108.9000  C105             C           1\n",
              "1034         1       Ryerson, Mr. Arthur Larned                           male    61.0  1      3      PC 17608  262.3750  B57 B59 B63 B66  C           1\n",
              "992          1       Stengel, Mrs. Charles Emil Henry (Annie May Morris)  female  43.0  1      0      11778     55.4417   C116             C           1\n",
              "1001         2       Swane, Mr. George                                    male    18.5  0      0      248734    13.0000   F                S           1\n",
              "1004         1       Evans, Miss. Edith Corse                             female  36.0  0      0      PC 17531  31.6792   A29              C           1\n",
              "                                                                                                                                                      ..\n",
              "1198         1       Allison, Mr. Hudson Joshua Creighton                 male    30.0  1      2      113781    151.5500  C22 C26          S           1\n",
              "1200         1       Hays, Mr. Charles Melville                           male    55.0  1      1      12749     93.5000   B69              S           1\n",
              "1206         1       White, Mrs. John Stuart (Ella Holmes)                female  55.0  0      0      PC 17760  135.6333  C32              C           1\n",
              "1208         1       Spencer, Mr. William Augustus                        male    57.0  1      0      PC 17569  146.5208  B78              C           1\n",
              "904          1       Snyder, Mrs. John Pillsbury (Nelle Stevenson)        female  23.0  1      0      21228     82.2667   B45              S           1\n",
              "Length: 87, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsA5M76pBv4U"
      },
      "source": [
        "The value_counts of test_data return the unique values.\n",
        "The output above show the unique occurences of the values for the whole data frame of test_data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm-gDdhPnsHV"
      },
      "source": [
        "### 4.3)\tPrepare a DataFrame that contains the following numeric fields: Survided, Sex, Age, SibSp, Parch, Fare. Plot these numeric fields on a histogram. Did you notice anything new using the histogram?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBA7vKpHdF5y"
      },
      "source": [
        "df = pd.DataFrame(train_data, columns = ['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDpCUdJUdGCt"
      },
      "source": [
        "Created pandas dataframe with the desired numeric fields.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw2YxJk7I23T",
        "outputId": "69a0cac9-b513-49af-aec6-fa9f03fbd34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame(train_data, columns = ['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'] )\n",
        "\n",
        "hist_plot = df.hist(bins= 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-tCAnIBQg6v"
      },
      "source": [
        "The histograms show the distribution of the data. For example, the fare histogram shows that is mostly skewed to the left. The survived histogram show its data is far apart from each other and have a high variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h909Pm31jEwg"
      },
      "source": [
        "### 4.4) Use groupby of Pandas to explain the following questions. Study the examples listed here for groupby and plot functions:\n",
        "-\thttps://towardsdatascience.com/pandas-groupby-explained-453692519d0\n",
        "-\thttps://medium.com/@sciencelee/making-plots-with-the-pandas-groupby-ac492941af28\n",
        "\n",
        "For the following examples, use group by and plot for example:\n",
        "> dataFrame.groupby(attribute1)[attribute2].median()\n",
        "\n",
        "> dataFrame.groupby(attribute1)[attribute2].median().plot(kind=bar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu1477mNWdt3"
      },
      "source": [
        "Created another dataframe with extra attributes needed for 4.4a-d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EggxYk_fVyba"
      },
      "source": [
        "df1 = pd.DataFrame(train_data, columns = ['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Pclass','Sex','Embarked']) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjhTnoVtmUZ6"
      },
      "source": [
        "\n",
        "#### 4.4) a)\tFind the average survival rate based on passenger class and plot the results.  What is the insight you gain? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhT8nHXOdJi0",
        "outputId": "49ee259a-ec04-4f26-e882-4cf99cfd6e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "df1.groupby(['Pclass'])['Survived'].mean()\n",
        "\n",
        "df1.groupby(['Pclass'])['Survived'].mean().plot(kind='bar')\n",
        "display(df1.groupby(['Pclass'])['Survived'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pclass\n",
              "1    0.629630\n",
              "2    0.472826\n",
              "3    0.242363\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCu5JESwdJry"
      },
      "source": [
        "The bar plot shows the survivial rate for each passenger class. It is not surprising to see that the first class had a higher survival rate than classes 2 and 3.\n",
        "I added the display to show the accurate precentage of the survivial rate per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItM_A5odeMp"
      },
      "source": [
        "----------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xLI07-BnNeZ"
      },
      "source": [
        "#### 4.4) b)\tFind the average survival rate based on sex and plot the results. What is the insight?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGbp6TkjdM7S",
        "outputId": "14692425-2cab-4ed8-b582-e434ef1acb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "train_data.groupby(['Sex'])['Survived'].mean()\n",
        "\n",
        "train_data.groupby(['Sex'])['Survived'].mean().plot(kind='bar')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff13de97358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt5gTpt7dOyf"
      },
      "source": [
        "Also, it not surprisng that females would survive more due to gender social norms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAQWARQidhoC"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXK82TXTj4Xo"
      },
      "source": [
        "#### 4.4) c) Find the median age by Pclass and Sex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmLY_eOdRAZ",
        "outputId": "bcb5e1ef-126c-410d-965d-61b6e1e81bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "train_data.groupby(['Pclass','Sex'])['Age'].median()\n",
        "\n",
        "train_data.groupby(['Pclass','Sex'])['Age'].median().plot(kind='bar')\n",
        "display(train_data.groupby(['Pclass','Sex'])['Age'].median())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pclass  Sex   \n",
              "1       female    35.0\n",
              "        male      40.0\n",
              "2       female    28.0\n",
              "        male      30.0\n",
              "3       female    21.5\n",
              "        male      25.0\n",
              "Name: Age, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnJxs7KEcYKf"
      },
      "source": [
        "The display method helps with showing the median age of each class based upon sex.\n",
        "It seems the median age of women is lower than that of men in each of the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCrB_0m6djE_"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgTF3jyXT0CY"
      },
      "source": [
        "#### 4.4) d)\tFind out the median fare based on passenger class and embarked place. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYu7JF2pdTnr",
        "outputId": "18cc7e8c-c0e8-4fd0-de4f-ccb4b683601f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "display(df1.groupby(['Pclass','Embarked'])['Fare'].median())\n",
        "\n",
        "df1.groupby(['Pclass','Embarked'])['Fare'].median().plot(kind='bar')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pclass  Embarked\n",
              "1       C           78.2667\n",
              "        Q           90.0000\n",
              "        S           52.0000\n",
              "2       C           24.0000\n",
              "        Q           12.3500\n",
              "        S           13.5000\n",
              "3       C            7.8958\n",
              "        Q            7.7500\n",
              "        S            8.0500\n",
              "Name: Fare, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1529311d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rNLm2QKdTvg"
      },
      "source": [
        "It seems passengers from the first class that embarked from 'Q' payed $90. The fare could have went up due to paying in advance due than closer to the departure date. Or these passengers payed for extra accommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9A_IHSTXIkL"
      },
      "source": [
        "-----------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Ql5NWAWwBZ"
      },
      "source": [
        "### 4.5) We will work on missing values on the whole data set. You can benefit from the following article for some of the questions below:\n",
        "- https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psvyLl4EXwlp"
      },
      "source": [
        "#### 4.5) a) Perform the followings:\n",
        "- 1) Create a new 'all_data' frame by appending test data to train data. \n",
        "\n",
        "- 2) Using pandas methods see and show that some indexes repeat. Find a way to Use re-organize the index so that they are unique and do not have an extra 'index' column.\n",
        "\n",
        "- 3) Then check the data using the info() method and list which columns have missing data (other than 'Survived')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcCgtabYduIl",
        "outputId": "a7758e1f-a7cf-4a88-c4d3-72aadc931cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1887
        }
      },
      "source": [
        "\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "all_data = train_data.append(test_data)\n",
        "repeated_indices = all_data.index.duplicated()\n",
        "pd.option_context('display.max_rows', None, 'display.max_columns', None)  \n",
        "print(repeated_indices)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8ZHENEpe9nj"
      },
      "source": [
        "The output prints where any of the indices are repeated. The duplicated method returns true if the index has been repeated.\n",
        "The set_printoptions is used how Numpy objects and arrays are displayed.\n",
        "Also, sys.maxsize is the maximum number of elements of the data_type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em0YDMScSfy4",
        "outputId": "5369c7b0-bd7a-481e-fd22-b790e90ba6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(all_data.index.drop_duplicates())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
            "            ...\n",
            "            881, 882, 883, 884, 885, 886, 887, 888, 889, 890],\n",
            "           dtype='int64', length=891)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h18NMbm1P16_"
      },
      "source": [
        "The code above is what I used to drop the duplicated indices.\n",
        "The drop_duplicates() is used to remove the duplicated indices. By default, the parameter keep is set to first. It keeps the first occurrence and will delete any duplicated occurrence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yPdBiwUFUOQ",
        "outputId": "1c5de5aa-cc0c-4696-df72-e0f03f55315d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "\n",
        "all_data.info()  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  1309 non-null   int64  \n",
            " 1   Survived     891 non-null    float64\n",
            " 2   Pclass       1309 non-null   int64  \n",
            " 3   Name         1309 non-null   object \n",
            " 4   Sex          1309 non-null   object \n",
            " 5   Age          1046 non-null   float64\n",
            " 6   SibSp        1309 non-null   int64  \n",
            " 7   Parch        1309 non-null   int64  \n",
            " 8   Ticket       1309 non-null   object \n",
            " 9   Fare         1308 non-null   float64\n",
            " 10  Cabin        295 non-null    object \n",
            " 11  Embarked     1307 non-null   object \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 172.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_MY8-vR74w"
      },
      "source": [
        "The all_data.info shows that Age, Fare, Cabin, and Embarked are the other attributes with missing values.\n",
        "Age: 263 missing values\n",
        "Fare: 1 missing value\n",
        "Cabin: 1014 missing values\n",
        "Embarked: 2 missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmGkVDBZG9d1",
        "outputId": "f4b898ee-7883-48fe-9b63-bd3d1dd2fd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "all_data.isnull()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1309 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass   Name  ...  Ticket   Fare  Cabin  Embarked\n",
              "0          False     False   False  False  ...   False  False   True     False\n",
              "1          False     False   False  False  ...   False  False  False     False\n",
              "2          False     False   False  False  ...   False  False   True     False\n",
              "3          False     False   False  False  ...   False  False  False     False\n",
              "4          False     False   False  False  ...   False  False   True     False\n",
              "..           ...       ...     ...    ...  ...     ...    ...    ...       ...\n",
              "413        False      True   False  False  ...   False  False   True     False\n",
              "414        False      True   False  False  ...   False  False  False     False\n",
              "415        False      True   False  False  ...   False  False   True     False\n",
              "416        False      True   False  False  ...   False  False   True     False\n",
              "417        False      True   False  False  ...   False  False   True     False\n",
              "\n",
              "[1309 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgAOkoLIduUB"
      },
      "source": [
        "I used .isnull() to verify the attributes that have missing values. Here, I can see that Survived,Age,and Cabin have missing values. I cannot see that Fare and Embarked have missing values based upon the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaay5ZK6YPZB"
      },
      "source": [
        "#### 4.5) b) Fill missing values of 'Age' field with the median age of the pasenger class and sex that you found for the question above. Use the apply method with lambda function. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8HAaRbbJAW",
        "outputId": "76a7df25-553e-434e-b9c2-34e45e8f21c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "all_data.loc[all_data['Age'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Williams, Mr. Charles Eugene</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>244373</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Masselmani, Mrs. Fatima</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2649</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Emir, Mr. Farred Chehab</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2631</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330959</td>\n",
              "      <td>7.8792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>1300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>334915</td>\n",
              "      <td>7.7208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>1302</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Naughton, Miss. Hannah</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>365237</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>263 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "5              6       0.0       3  ...   8.4583   NaN         Q\n",
              "17            18       1.0       2  ...  13.0000   NaN         S\n",
              "19            20       1.0       3  ...   7.2250   NaN         C\n",
              "26            27       0.0       3  ...   7.2250   NaN         C\n",
              "28            29       1.0       3  ...   7.8792   NaN         Q\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "408         1300       NaN       3  ...   7.7208   NaN         Q\n",
              "410         1302       NaN       3  ...   7.7500   NaN         Q\n",
              "413         1305       NaN       3  ...   8.0500   NaN         S\n",
              "416         1308       NaN       3  ...   8.0500   NaN         S\n",
              "417         1309       NaN       3  ...  22.3583   NaN         C\n",
              "\n",
              "[263 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKm8b9TSUVww"
      },
      "source": [
        "The code above was used to see how many missing values of Age. The info method let me know that I was missing 263 values. The output here confirms that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TmWACb5dwsK",
        "outputId": "6f1e5814-a500-48b5-9cf0-1c21d92fc0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "age_fill = all_data.groupby(['Pclass','Sex'])[\"Age\"].apply(lambda x: x.fillna(x.median()))\n",
        "age = age_fill.to_frame()\n",
        "age.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 890\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Age     1309 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 20.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBSf4qpFU6NE"
      },
      "source": [
        "The code above  was used to fill missing values of 'Age' with the median age of the Pclass and Sex. I used the info() to check if those values have been fill in. It tells me that the Age have 1309 non-null values. If the Age column was not filled in correctly, it would still read as 1046."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09wpwgZOdw1i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pLjO1ktaQBn"
      },
      "source": [
        "#### 4.5) c) Fill missing values of 'Fare' field with the median fare of the pasenger class and embarked location that you found for the question above. Use the apply method with lambda function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Z1uTlv4MVX",
        "outputId": "be74955e-3566-4e0c-8d40-7bb2069c06ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "all_data.loc[all_data['Fare'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>1044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Storey, Mr. Thomas</td>\n",
              "      <td>male</td>\n",
              "      <td>60.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3701</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ... Fare Cabin  Embarked\n",
              "152         1044       NaN       3  ...  NaN   NaN         S\n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6cxSfOWW4N"
      },
      "source": [
        "The code above was used to see how many missing values of Fare. The info method let me know that I was missing 1 value. The output here confirms that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTtdSfWZUBRK",
        "outputId": "1ebabf15-1d55-4685-d65d-5721d636bfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "fare_fill = all_data.groupby(['Pclass','Embarked'])[\"Fare\"].apply(lambda x: x.fillna(x.median()))\n",
        "fare = fare_fill.to_frame()\n",
        "fare.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1308 entries, 0 to 890\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Fare    1308 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 20.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1hl3Vk6Wszx"
      },
      "source": [
        "The code above was used to fill missing values of 'Fare' with the median age of the Pclass and Embarked. I used the info() to check if those values have been fill in. It tells me that the Fare have 1 non-null value. If the Fare column was not filled in correctly, it would still read as 1308."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glJEC9N6EhqN"
      },
      "source": [
        "#### 4.5) d) Fill missing values of 'Cabin' field with the 'NA' value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdwDGkyy5E7j",
        "outputId": "8d93df28-6b02-47f7-fd29-fdadaf95e4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "all_data.loc[all_data['Cabin'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>1304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
              "      <td>female</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>347086</td>\n",
              "      <td>7.7750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1014 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1       0.0       3  ...   7.2500   NaN         S\n",
              "2              3       1.0       3  ...   7.9250   NaN         S\n",
              "4              5       0.0       3  ...   8.0500   NaN         S\n",
              "5              6       0.0       3  ...   8.4583   NaN         Q\n",
              "7              8       0.0       3  ...  21.0750   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "412         1304       NaN       3  ...   7.7750   NaN         S\n",
              "413         1305       NaN       3  ...   8.0500   NaN         S\n",
              "415         1307       NaN       3  ...   7.2500   NaN         S\n",
              "416         1308       NaN       3  ...   8.0500   NaN         S\n",
              "417         1309       NaN       3  ...  22.3583   NaN         C\n",
              "\n",
              "[1014 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bKvOvZRXVH2"
      },
      "source": [
        "The code above was used to see how many missing values of Cabin. The info method let me know that I was missing 1014 values. The output here confirms that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Qmbysod1P7",
        "outputId": "9c53e868-4f6b-43bb-b72d-7fedf86fb253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "cabin_fill =all_data['Cabin'].fillna('NA')\n",
        "cabin = cabin_fill.to_frame()\n",
        "cabin.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Cabin   1309 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 60.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsd-k20bd1bu"
      },
      "source": [
        "The code above was used to fill missing values of 'Cabin' with NA. I used the info() to check if those values have been fill in. It tells me that the cabin have 1309 non-null values. If the cabin column was not filled in correctly, it would still read as 1046."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uaurJv6EtY_"
      },
      "source": [
        "#### 4.5) e) Fill missing values of 'Embarked' field with the most frequently seen 'Embarked' value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKOd82FsOdHz",
        "outputId": "5c97f444-49b9-4e5f-84e2-18a9074c7500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "all_data['Embarked']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      S\n",
              "1      C\n",
              "2      S\n",
              "3      S\n",
              "4      S\n",
              "      ..\n",
              "413    S\n",
              "414    C\n",
              "415    S\n",
              "416    S\n",
              "417    C\n",
              "Name: Embarked, Length: 1309, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT4ylWoLXzRt"
      },
      "source": [
        "I printed out the Embarked column of all_data here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7_q_kdb5LZp",
        "outputId": "4f4322ff-7c37-4a1f-e495-5865da2140fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "all_data.loc[all_data['Embarked'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>62</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Icard, Miss. Amelie</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113572</td>\n",
              "      <td>80.0</td>\n",
              "      <td>B28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
              "      <td>female</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113572</td>\n",
              "      <td>80.0</td>\n",
              "      <td>B28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...  Fare Cabin  Embarked\n",
              "61            62       1.0       1  ...  80.0   B28       NaN\n",
              "829          830       1.0       1  ...  80.0   B28       NaN\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG1VkeeUX7gt"
      },
      "source": [
        "The code above was used to see how many missing values of Embarked. The info method let me know that I was missing 2 values. The output here confirms that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwaPbBogrka-",
        "outputId": "8f3ef29c-0c4c-4f2c-934c-20a54e06496d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "all_data['Embarked'].mode()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    S\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VDgI70cYOxM"
      },
      "source": [
        "I am suppose to fill in the 2 missing values with the frequent Embarked value. I thought this meant that I needed to get the mode for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNpZ-S5lLzT",
        "outputId": "3f1defd2-7cbb-4bd0-838d-5bb13eeaaf6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "embark_fill = all_data['Embarked'].fillna('0')\n",
        "embark = embark_fill.to_frame()\n",
        "embark.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Embarked  1309 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 60.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0_B7QGHd35b"
      },
      "source": [
        "The code above was used to fill missing values of 'Embarked' with its frequent Embarked value. I used the info() to check if those values have been fill in. It tell me that it now have 1309 non-null values. If the Embarked column was not filled in correctly, it would still read as 1307."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gPdPAa7Fvmr"
      },
      "source": [
        "### 4.6) Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSAEAZk2ZhtF"
      },
      "source": [
        "#### 4.6) a) Create a new feature 'Family_Size'\n",
        "- Create a new feature 'Family_Size' using other features (and also adding the person him/herself to the family size). \n",
        "- Then plot a bar chart to show how many of each 'Family_Size' value exists. \n",
        "- Finally plot a bar chart to show the relationship between 'Family_Size' and the 'Survival' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMkJflwYd74r",
        "outputId": "aba2be94-dbb1-423e-a469-c74c27e3876f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "all_data['Family_size'] = all_data['SibSp'] + all_data['Parch'] + all_data['Pclass']\n",
        "all_data['Family_size'].value_counts().plot(kind='bar')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1527c8eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S07mRro-aNmc"
      },
      "source": [
        "Family_size was created by Sibsp,Parch, and Pclass. I felt that the Sibsp and Parch were obvious because, it tell # of siblings / spouses and  # of parents / children aboard the Titanic. I added Pclass because I would assume the the family would be in the same passenger class. Then, I used value_counts() to retrieve the counts of the unique rows of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLkm0tVYZw2",
        "outputId": "789146b0-7c04-4a9f-f083-cd7f90b1bbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "\n",
        "(all_data.groupby(['Family_size'])['Survived'].mean()).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1529e0278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ9vyPGWd8BR"
      },
      "source": [
        "I created a bar chart of the average survival rate based upon family size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR1B_JwlG_x6"
      },
      "source": [
        "#### 4.6) b) Create a new feature 'Fare_Category'\n",
        "- Use qcut method of Pandas for creating 'Fare_Category' field from Fare so that we have 5 categories of Fare. Note that: 1) With qcut We decompose a distribution so that there are (approximately) the same number of cases ineach category. 2) qcut returns categorical data and we need to convert it to string using astype(str). Otherwise one-hot-encoder question below might have issues.\n",
        "- Use value_counts() method to show the results. \n",
        "- Plot a bar chart to show the relationship between 'Fare_Category' and the 'Survival'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01X1bStCd-qn",
        "outputId": "7d3dc080-bb53-4374-e5c8-5fe3fa1ce0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "all_data['Fare_Category'] = pd.qcut(all_data['Fare'],5)\n",
        "\n",
        "print((all_data['Fare_Category'].astype(str)).value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.001, 7.854]      275\n",
            "(21.679, 41.579]     262\n",
            "(41.579, 512.329]    259\n",
            "(10.5, 21.679]       258\n",
            "(7.854, 10.5]        254\n",
            "nan                    1\n",
            "Name: Fare_Category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niroiWkuc6Ii"
      },
      "source": [
        "The qcut method  is a quantile-based discretization functon and is used on the Fare_Category. The categorical data was converted to string then, the value_counts of the Fare_Category was taken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mAhdx-F3G66",
        "outputId": "6d1af302-68a7-46c8-d481-c47687388b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "(all_data.groupby(['Fare_Category'])['Survived'].mean()).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff152955278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shvdkgjd-2j"
      },
      "source": [
        "I created a bar chart of the average survival rate based upon the Fare_Category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58hnI5BCHo7N"
      },
      "source": [
        "#### 4.6) c) Create a new feature 'Age_Category'\n",
        "- Use cut method of Pandas for creating 'Age_Category' field from Age so that we have 5 categories of Age. Note that: 1) With cut, the bins are formed based on the values of the variable, regardless of how many cases fall into a category. 2) cut returns categorical data and we need to convert it to string using astype(str). Otherwise one-hot-encoder question below might have issues.\n",
        "\n",
        "- Use value_counts() method to show the results. \n",
        "- Plot a bar chart to show the relationship between 'Age_Category' and the 'Survival'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Jk4YTEeBsm",
        "outputId": "8b27a7fc-86d0-4249-eccb-4bc613f91e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "all_data['Age_Category'] = pd.cut(all_data['Age'],5)\n",
        "\n",
        "print((all_data['Age_Category'].astype(str).value_counts()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16.136, 32.102]    524\n",
            "(32.102, 48.068]    269\n",
            "nan                 263\n",
            "(0.0902, 16.136]    134\n",
            "(48.068, 64.034]    106\n",
            "(64.034, 80.0]       13\n",
            "Name: Age_Category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTvzrQeKemvC"
      },
      "source": [
        "The cut method is used to segment and sort  data values into bins. The data was converted to string then, the value_counts of the Age_Category was taken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTahblLf3VS7",
        "outputId": "d909dc87-f018-4a4d-c9f7-d8dfc6dbad50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "(all_data.groupby(['Age_Category'])['Survived'].mean()).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff13dc0ba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2-Kyqx5eB5f"
      },
      "source": [
        "I created a bar chart of the average survival rate based upon the Age_Category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHDDLP94e5HK"
      },
      "source": [
        "### 4.7) Encoders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_qBVUXyZahG"
      },
      "source": [
        "#### 4.7) a) Using LabelEncoder, create the 'Sex_Numeric' based on the values of the 'Sex' attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R06_YosYeE3P",
        "outputId": "bf1826ea-6b5f-4d1b-f545-2573be16b9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " \n",
        "# Import label encoder \n",
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Sex attribute. \n",
        "all_data['Sex']= label_encoder.fit_transform(all_data['Sex']) \n",
        "  \n",
        "all_data['Sex'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IOjiorLeFBF"
      },
      "source": [
        "Label Encoding refers to converting the labels into numeric form and converting it into the machine-readable form. It encode target labels with value between 0 and n_classes-1.the fit_transform fits the label encoder and return encoded labels. This was  done on the Sex attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsq00_8fgoSY"
      },
      "source": [
        "#### 4.7) b) Use OneHotEncoder to create new attributes for the 'Embarked' attribute.\n",
        "\n",
        "Note: You can benefit from the following article for One-Hot-Encoding questions:\n",
        "- https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxsjZjgzeHZo",
        "outputId": "b6b32602-8235-4a4a-8f54-9cec10701520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22270
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "# passing Embarked column (label encoded values of Embarked)\n",
        "encoded_feat = OneHotEncoder().fit_transform(embark['Embarked'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mQHWJpNeHuB"
      },
      "source": [
        "OneHotEndcoder() was used to convert Embarked' categorical values to numerical values.The fit_transform() is used to fit OneHotEncoder to X, then transform X. In my case, X equals to embark['Embarked'].values.reshape(-1,1).\n",
        "The .toarray() return a dense ndarray representation of the matrix but first the values and reshape was used. The reshape gives a new shape to an array without changing its data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF5XlDX_Y95d",
        "outputId": "b37de99c-ebff-421c-e7b0-65c61dbd6673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "all_data['Fare_Category'].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-0.001, 7.854], (41.579, 512.329], (7.854, 10.5], (41.579, 512.329], (7.854, 10.5], ..., (7.854, 10.5], (41.579, 512.329], (-0.001, 7.854], (7.854, 10.5], (21.679, 41.579]]\n",
              "Length: 1309\n",
              "Categories (5, interval[float64]): [(-0.001, 7.854] < (7.854, 10.5] < (10.5, 21.679] <\n",
              "                                    (21.679, 41.579] < (41.579, 512.329]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyS4d5Fs9sDm"
      },
      "source": [
        "Here, I printed out the Fare_Category to check what values it will give me before using the one hot encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRb4iOZxOSWN"
      },
      "source": [
        "#### 4.7) c) Use OneHotEncoder to create new attributes for the 'Fare_Category' attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgneNQ0eKQO",
        "outputId": "7e590793-1488-4e45-c578-cf0921e153fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22270
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "Fare_Category = all_data['Fare_Category'].astype(str)\n",
        "Fare_c = Fare_Category.to_frame()\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "# passing Fare_Category column (label encoded values of Fare_Category)\n",
        "encoded_feat = OneHotEncoder().fit_transform(Fare_c['Fare_Category'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPVyaq4UeKgN"
      },
      "source": [
        "OneHotEndcoder() was used to convert Fare_Category's categorical values to numerical values.The fit_transform() is used to fit OneHotEncoder to X, then transform X.\n",
        " In my case, X equals to (Fare_c['Fare_Category'].values.reshape(-1,1). The .toarray() return a dense ndarray representation of the matrix but first the values and reshape was used. The reshape gives a new shape to an array without changing its data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BommJmQ9Oeqq"
      },
      "source": [
        "#### 4.7) d) Use OneHotEncoder to create new attributes for the 'Age_Category' attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeqPavl4eNMo",
        "outputId": "0f969c68-4e3a-44f0-d495-c8db903d2d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22270
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "Age_Category = all_data['Age_Category'].astype(str)\n",
        "Age_c = Age_Category.to_frame()\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "# passing Age_Category column (label encoded values of Age_Category)\n",
        "encoded_feat = OneHotEncoder().fit_transform(Age_c['Age_Category'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gsbTz-AeNV2"
      },
      "source": [
        "OneHotEndcoder() was used to convert Fare_Category's categorical values to numerical values.The fit_transform() is used to fit OneHotEncoder to X, then transform X. In my case, X equals to (Age_c['Age_Category'].values.reshape(-1,1). The .toarray() return a dense ndarray representation of the matrix but first the values and reshape was used. The reshape gives a new shape to an array without changing its data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1WN1k2z2JM"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEVq4omFypA5"
      },
      "source": [
        "### 4.8) Create the correlation matrix for the all_data data frame and show the values for 'Survived' column in an descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBoyga8ZeRWv",
        "outputId": "cce2064a-4913-4358-904a-42b511cc9fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "corrM_all_data= all_data.corr() \n",
        "  \n",
        "print(corrM_all_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             PassengerId  Survived    Pclass  ...     Parch      Fare  Family_size\n",
            "PassengerId     1.000000 -0.005007 -0.038354  ...  0.008942  0.031428    -0.044807\n",
            "Survived       -0.005007  1.000000 -0.338481  ...  0.081629  0.257307    -0.137303\n",
            "Pclass         -0.038354 -0.338481  1.000000  ...  0.018322 -0.558629     0.501596\n",
            "Sex             0.013406 -0.543351  0.124617  ... -0.213125 -0.185523    -0.106241\n",
            "Age             0.028814 -0.077221 -0.408106  ... -0.150917  0.178740    -0.405513\n",
            "SibSp          -0.055224 -0.035322  0.060832  ...  0.373587  0.160238     0.774488\n",
            "Parch           0.008942  0.081629  0.018322  ...  1.000000  0.221539     0.694673\n",
            "Fare            0.031428  0.257307 -0.558629  ...  0.221539  1.000000    -0.059768\n",
            "Family_size    -0.044807 -0.137303  0.501596  ...  0.694673 -0.059768     1.000000\n",
            "\n",
            "[9 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R41sRVd2CG0I"
      },
      "source": [
        "A correlation matrix was created for the all_data dataframe. The .corr() by default present values in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyfHC40b-x4H",
        "outputId": "825887e1-2c40-444e-cf74-81a2d40ce0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "corrM_all_data= all_data.corr() \n",
        "  \n",
        "print(corrM_all_data.sort_values(by=['Survived'],ascending=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             PassengerId  Survived    Pclass  ...     Parch      Fare  Family_size\n",
            "Survived       -0.005007  1.000000 -0.338481  ...  0.081629  0.257307    -0.137303\n",
            "Fare            0.031428  0.257307 -0.558629  ...  0.221539  1.000000    -0.059768\n",
            "Parch           0.008942  0.081629  0.018322  ...  1.000000  0.221539     0.694673\n",
            "PassengerId     1.000000 -0.005007 -0.038354  ...  0.008942  0.031428    -0.044807\n",
            "SibSp          -0.055224 -0.035322  0.060832  ...  0.373587  0.160238     0.774488\n",
            "Age             0.028814 -0.077221 -0.408106  ... -0.150917  0.178740    -0.405513\n",
            "Family_size    -0.044807 -0.137303  0.501596  ...  0.694673 -0.059768     1.000000\n",
            "Pclass         -0.038354 -0.338481  1.000000  ...  0.018322 -0.558629     0.501596\n",
            "Sex             0.013406 -0.543351  0.124617  ... -0.213125 -0.185523    -0.106241\n",
            "\n",
            "[9 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHV5wEh8eRhz"
      },
      "source": [
        "Here, I sorted the values by using sort_values. I  set by to the column I wanted which is Survived and chose ascending to be False in order for the values to be descending."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrSvKGXOGn3x"
      },
      "source": [
        "## 5) Run all of your code and get your output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHc95F7CGupC"
      },
      "source": [
        "## 6) Print the latest status of your notebook to a pdf file \n",
        "- The pdf file must include the link of your jupyter notebook page (see step 2 above)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcLDxwqrG3Zx"
      },
      "source": [
        "## 7) Submit the PDF file on Canvas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfBF5asJUySS",
        "outputId": "ef6006f4-d948-4ef7-850b-3df6a246148f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('Project_Titanic_AlexisD.ipynb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-18 20:08:03--  https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1301 (1.3K) [text/plain]\n",
            "Saving to: colab_pdf.py\n",
            "\n",
            "colab_pdf.py        100%[===================>]   1.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-18 20:08:03 (99.4 MB/s) - colab_pdf.py saved [1301/1301]\n",
            "\n",
            "Mounted at /content/drive/\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,681 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [860 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,150 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,112 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [231 kB]\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [335 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,733 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,348 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.0 kB]\n",
            "Fetched 10.8 MB in 2s (5,175 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto apache2 | lighttpd | httpd poppler-utils ghostscript\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf-reader\n",
            "  | pdf-viewer texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-generic-recommended\n",
            "  texlive-latex-base texlive-latex-extra texlive-latex-recommended\n",
            "  texlive-pictures texlive-plain-generic texlive-xetex tipa\n",
            "0 upgraded, 47 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 146 MB of archives.\n",
            "After this operation, 460 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.13 [5,092 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.13 [2,263 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.6 [48.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.6 [3,069 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-generic-recommended all 2017.20180305-1 [15.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-xetex all 2017.20180305-1 [10.7 MB]\n",
            "Fetched 146 MB in 2s (78.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 144611 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../06-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../07-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../08-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../09-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../10-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../11-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../12-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.13_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.26~dfsg+0-0ubuntu0.18.04.13_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../14-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../15-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../16-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../17-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../18-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../19-ruby2.5_2.5.1-1ubuntu1.6_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.6) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../20-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../21-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../22-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../23-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../24-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../25-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../26-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../27-libruby2.5_2.5.1-1ubuntu1.6_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.6) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../28-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../29-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../30-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../31-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../32-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../33-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../34-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../35-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../36-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../37-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../38-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../39-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-generic-recommended.\n",
            "Preparing to unpack .../40-texlive-generic-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-generic-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../41-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../42-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../43-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../44-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../45-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../46-texlive-xetex_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-xetex (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-generic-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up texlive-xetex (2017.20180305-1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.6) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.6) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/Project_Titanic_AlexisD.ipynb to pdf\n",
            "[NbConvertApp] Support files will be in Project_Titanic_AlexisD_files/\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_AlexisD_files\n",
            "[NbConvertApp] Writing 190328 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: [u'bibtex', u'./notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 174747 bytes to /content/drive/My Drive/Project_Titanic_AlexisD.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_14a638d1-56cf-45c1-941c-8ba4cd16455c\", \"Project_Titanic_AlexisD.pdf\", 174747)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File ready to be Downloaded and Saved to Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    }
  ]
}