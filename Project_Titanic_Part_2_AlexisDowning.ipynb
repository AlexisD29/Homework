{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Project_Titanic_Part_2_AlexisDowning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexisD29/Homework/blob/master/Project_Titanic_Part_2_AlexisDowning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbOytv4mz_lx"
      },
      "source": [
        "# Project 1 - Titanic - Part 2 - Alexis Downing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGbgOa8z_ly"
      },
      "source": [
        "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.\n",
        "\n",
        "## 1) Upload this jupyter notebook page to your colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD05VVzIE_im"
      },
      "source": [
        "## 2) Get the Shareable link for your page and update the URL below for your Jupyter Notebook:\n",
        "- _Make sure you select __'Anyone with the Link'__ option_\n",
        "\n",
        "__This jupyter notebook page is located at__: YOUR LINK HERE\n",
        "\n",
        "We will click on the link above to visit to your Jupyter Notebook page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYRaIawfz_l0"
      },
      "source": [
        "## 3) Downloaded the data (train.csv and test.csv files) from Kaggle and then upload them using the first code block below. \n",
        "- To download the files, login to [Kaggle](https://www.kaggle.com/) and go to the [Titanic challenge](https://www.kaggle.com/c/titanic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ucl-YDyF9yu"
      },
      "source": [
        "Keep the following code block as it is. Use it to upload the donwloaded csv files and to save them into your colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Eb5SNhz_l6",
        "outputId": "1a26df5f-b0ef-4020-955e-bfb95bb14aab",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "\n",
        "train_data_dict = files.upload() #uploads as a disctionary and creates a file\n",
        "os.remove('train.csv') #remove the file created during upload that is in the root folder\n",
        "train_data = pd.read_csv(io.StringIO(train_data_dict['train.csv'].decode('utf-8')),sep=',') #get the data from the dictionary to the dataframe\n",
        "\n",
        "test_data_dict = files.upload() #uploads as a disctionary and creates a file\n",
        "os.remove('test.csv') #remove the file created during upload that is in the root folder\n",
        "test_data = pd.read_csv(io.StringIO(test_data_dict['test.csv'].decode('utf-8')),sep=',') #get the data from the dictionary to the dataframe\n",
        "\n",
        "titanic_dir_path = os.path.join(\"datasets\", \"titanic\")\n",
        "os.makedirs(titanic_dir_path, exist_ok=True) #create the folder\n",
        "train_csv_path = os.path.join(titanic_dir_path, \"train.csv\") #create the path for the csv file \n",
        "test_csv_path = os.path.join(titanic_dir_path, \"test.csv\") #create the path for the csv file\n",
        "\n",
        "train_data.to_csv(train_csv_path, index=False) #save the data to csv file\n",
        "test_data.to_csv(test_csv_path, index=False) #save the data to csv file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3b8205a-962e-47ff-8e7b-2c69d47055ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3b8205a-962e-47ff-8e7b-2c69d47055ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30abe181-bdf4-4a24-acf4-a1abdb7da101\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30abe181-bdf4-4a24-acf4-a1abdb7da101\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r504INxDG_1"
      },
      "source": [
        "Once you upload the data, they will be saved into the `datasets/titanic` directory. After uploading, you don't need to upload them again. You can start run your code starting the below code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipoqlpnxz_l8"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "titanic_dir_path = os.path.join(\"datasets\", \"titanic\")\n",
        "train_csv_path = os.path.join(titanic_dir_path, \"train.csv\") #create the path for the csv file \n",
        "test_csv_path = os.path.join(titanic_dir_path, \"test.csv\") #create the path for the csv file\n",
        "\n",
        "train_data = pd.read_csv(train_csv_path)\n",
        "test_data = pd.read_csv(test_csv_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFN3j2OPm1NX"
      },
      "source": [
        "## 4) Part 1 Solutions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHCjFiYIXMe9",
        "outputId": "4040a100-db89-4dc7-cb0f-a48bdc04ee91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_data = train_data.append(test_data) # important\n",
        "all_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  1309 non-null   int64  \n",
            " 1   Survived     891 non-null    float64\n",
            " 2   Pclass       1309 non-null   int64  \n",
            " 3   Name         1309 non-null   object \n",
            " 4   Sex          1309 non-null   object \n",
            " 5   Age          1046 non-null   float64\n",
            " 6   SibSp        1309 non-null   int64  \n",
            " 7   Parch        1309 non-null   int64  \n",
            " 8   Ticket       1309 non-null   object \n",
            " 9   Fare         1308 non-null   float64\n",
            " 10  Cabin        295 non-null    object \n",
            " 11  Embarked     1307 non-null   object \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 132.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SLJYzIiBve_"
      },
      "source": [
        "all_data.reset_index(inplace = True, drop = True) # reset the inde inplace and drop the created extra 'index' column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBvugB1KbSKD"
      },
      "source": [
        "# Fill in missing age information based on the median age for its class and sex.\n",
        "all_data['Age'] = all_data.groupby(['Pclass','Sex'])['Age'].apply(lambda x : x.fillna(x.median()))\n",
        "\n",
        "all_data.Cabin = all_data.Cabin.fillna('NA')\n",
        "\n",
        "# Create a new feature by adding SibSp, Parch and the person herself. \n",
        "all_data['Family_Size'] = all_data['SibSp'] + all_data['Parch'] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uetSvIgCcaHQ",
        "outputId": "d655ed92-5543-4edd-cce1-6460794507d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fill in missing Embarked based on the most frequent Embarked\n",
        "all_data['Embarked'].fillna(all_data['Embarked'].mode()[0], inplace = True)\n",
        "\n",
        "# Fill in missing fare based on its class and embarked place\n",
        "all_data['Fare'] = all_data.groupby(['Pclass','Embarked'])['Fare'].apply(lambda x : x.fillna(x.median()))\n",
        "all_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 13 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  1309 non-null   int64  \n",
            " 1   Survived     891 non-null    float64\n",
            " 2   Pclass       1309 non-null   int64  \n",
            " 3   Name         1309 non-null   object \n",
            " 4   Sex          1309 non-null   object \n",
            " 5   Age          1309 non-null   float64\n",
            " 6   SibSp        1309 non-null   int64  \n",
            " 7   Parch        1309 non-null   int64  \n",
            " 8   Ticket       1309 non-null   object \n",
            " 9   Fare         1309 non-null   float64\n",
            " 10  Cabin        1309 non-null   object \n",
            " 11  Embarked     1309 non-null   object \n",
            " 12  Family_Size  1309 non-null   int64  \n",
            "dtypes: float64(3), int64(5), object(5)\n",
            "memory usage: 133.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhvdaHzLFOfH",
        "outputId": "88a95f52-2b8e-40d4-8bcf-704a3b3ed03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results_categorical = pd.qcut(all_data['Fare'],5)\n",
        "all_data['Fare_Category'] = pd.Series(results_categorical).astype(str)\n",
        "all_data['Fare_Category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.001, 7.854]      275\n",
              "(21.558, 41.579]     265\n",
              "(41.579, 512.329]    259\n",
              "(7.854, 10.5]        255\n",
              "(10.5, 21.558]       255\n",
              "Name: Fare_Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLGD3tX7kwaF",
        "outputId": "1f991529-b068-4622-b756-17cbf0e62859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results_categorical = pd.cut(all_data['Age'].astype(int),5)\n",
        "all_data['Age_Category'] = pd.Series(results_categorical).astype(str)\n",
        "all_data['Age_Category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16.0, 32.0]     752\n",
              "(32.0, 48.0]     304\n",
              "(-0.08, 16.0]    134\n",
              "(48.0, 64.0]     106\n",
              "(64.0, 80.0]      13\n",
              "Name: Age_Category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PcYtwhhfcOM",
        "outputId": "709b6415-eebd-4e37-fc4d-172dfd486b81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "all_data['Sex_Numeric'] = LabelEncoder().fit_transform(all_data['Sex'])\n",
        "all_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 16 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   PassengerId    1309 non-null   int64  \n",
            " 1   Survived       891 non-null    float64\n",
            " 2   Pclass         1309 non-null   int64  \n",
            " 3   Name           1309 non-null   object \n",
            " 4   Sex            1309 non-null   object \n",
            " 5   Age            1309 non-null   float64\n",
            " 6   SibSp          1309 non-null   int64  \n",
            " 7   Parch          1309 non-null   int64  \n",
            " 8   Ticket         1309 non-null   object \n",
            " 9   Fare           1309 non-null   float64\n",
            " 10  Cabin          1309 non-null   object \n",
            " 11  Embarked       1309 non-null   object \n",
            " 12  Family_Size    1309 non-null   int64  \n",
            " 13  Fare_Category  1309 non-null   object \n",
            " 14  Age_Category   1309 non-null   object \n",
            " 15  Sex_Numeric    1309 non-null   int64  \n",
            "dtypes: float64(3), int64(6), object(7)\n",
            "memory usage: 163.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEwCXYmq3Tb6"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "def encode_category_to_numeric(feature,data_frame):\n",
        "  encoded_feat = OneHotEncoder().fit_transform(data_frame[feature].values.reshape(-1,1)).toarray()\n",
        "  #number_unique = data_frame[feature].nunique()\n",
        "  unique_values = data_frame[feature].unique()\n",
        "  sorted_unique_value = np.sort(unique_values)\n",
        "  cols = ['{}_{}'.format(feature,value) for value in sorted_unique_value]\n",
        "  encoded_data = pd.DataFrame(encoded_feat, columns=cols)\n",
        "  return encoded_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xE9FQuU3_cF"
      },
      "source": [
        "encoded_data = encode_category_to_numeric('Embarked',all_data)\n",
        "all_data = pd.concat([all_data, encoded_data], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVTSb-Gl-HWM"
      },
      "source": [
        "encoded_data = encode_category_to_numeric('Fare_Category',all_data)\n",
        "all_data = pd.concat([all_data, encoded_data], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7xIRJMl3Q5X",
        "outputId": "f820e7fa-47c6-405f-ba5e-185c7aa3f38a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_data = encode_category_to_numeric('Age_Category',all_data)\n",
        "all_data = pd.concat([all_data, encoded_data], axis=1)\n",
        "all_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 29 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   PassengerId                      1309 non-null   int64  \n",
            " 1   Survived                         891 non-null    float64\n",
            " 2   Pclass                           1309 non-null   int64  \n",
            " 3   Name                             1309 non-null   object \n",
            " 4   Sex                              1309 non-null   object \n",
            " 5   Age                              1309 non-null   float64\n",
            " 6   SibSp                            1309 non-null   int64  \n",
            " 7   Parch                            1309 non-null   int64  \n",
            " 8   Ticket                           1309 non-null   object \n",
            " 9   Fare                             1309 non-null   float64\n",
            " 10  Cabin                            1309 non-null   object \n",
            " 11  Embarked                         1309 non-null   object \n",
            " 12  Family_Size                      1309 non-null   int64  \n",
            " 13  Fare_Category                    1309 non-null   object \n",
            " 14  Age_Category                     1309 non-null   object \n",
            " 15  Sex_Numeric                      1309 non-null   int64  \n",
            " 16  Embarked_C                       1309 non-null   float64\n",
            " 17  Embarked_Q                       1309 non-null   float64\n",
            " 18  Embarked_S                       1309 non-null   float64\n",
            " 19  Fare_Category_(-0.001, 7.854]    1309 non-null   float64\n",
            " 20  Fare_Category_(10.5, 21.558]     1309 non-null   float64\n",
            " 21  Fare_Category_(21.558, 41.579]   1309 non-null   float64\n",
            " 22  Fare_Category_(41.579, 512.329]  1309 non-null   float64\n",
            " 23  Fare_Category_(7.854, 10.5]      1309 non-null   float64\n",
            " 24  Age_Category_(-0.08, 16.0]       1309 non-null   float64\n",
            " 25  Age_Category_(16.0, 32.0]        1309 non-null   float64\n",
            " 26  Age_Category_(32.0, 48.0]        1309 non-null   float64\n",
            " 27  Age_Category_(48.0, 64.0]        1309 non-null   float64\n",
            " 28  Age_Category_(64.0, 80.0]        1309 non-null   float64\n",
            "dtypes: float64(16), int64(6), object(7)\n",
            "memory usage: 296.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csjM3R6KyyqJ",
        "outputId": "9288ec8a-c20d-45ad-bbbc-28faa8167345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corr_matrix = all_data.corr()\n",
        "corr_matrix[\"Survived\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived                           1.000000\n",
              "Fare_Category_(41.579, 512.329]    0.263007\n",
              "Fare                               0.257307\n",
              "Embarked_C                         0.168240\n",
              "Age_Category_(-0.08, 16.0]         0.121485\n",
              "Parch                              0.081629\n",
              "Fare_Category_(21.558, 41.579]     0.062529\n",
              "Fare_Category_(10.5, 21.558]       0.043153\n",
              "Age_Category_(32.0, 48.0]          0.032801\n",
              "Age_Category_(48.0, 64.0]          0.030350\n",
              "Family_Size                        0.016639\n",
              "Embarked_Q                         0.003650\n",
              "PassengerId                       -0.005007\n",
              "SibSp                             -0.035322\n",
              "Age                               -0.058635\n",
              "Age_Category_(64.0, 80.0]         -0.067344\n",
              "Age_Category_(16.0, 32.0]         -0.106821\n",
              "Embarked_S                        -0.149683\n",
              "Fare_Category_(-0.001, 7.854]     -0.171109\n",
              "Fare_Category_(7.854, 10.5]       -0.191707\n",
              "Pclass                            -0.338481\n",
              "Sex_Numeric                       -0.543351\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0pfM4bPDPlu"
      },
      "source": [
        "## 5)  Part 2 Questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVZOPDGKngj3"
      },
      "source": [
        "### 5) a) More feature engineering: Similar to what you have done for 'Age', 'Fare' and 'Embarked', use one hot encoder to prepare new features for Pclass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2wZeMhjlZqe",
        "outputId": "ceca8adb-cbea-4cf8-ec8f-7775c3006286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "# passing Pclass column (label encoded values of Pclass)\n",
        "encoded_feat = OneHotEncoder().fit_transform(all_data['Pclass'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiHccK1Nl3mN"
      },
      "source": [
        "### 5) b) Convert 'Sex_Numeric' and 'Family_Size' fields to 'float16' and then calculate  correlations matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWdxOrYHlcZ8",
        "outputId": "4161df40-5eab-4e54-d981-59afbcb14c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Converted_Sex_Numeric = all_data['Sex_Numeric'].astype('float16')\n",
        "#Converted_Sex_Numeric for the the correlation matrix will be represented by the variable corrM_CSN\n",
        "\n",
        "Converted_Family_Size = all_data['Family_Size'].astype('float16')\n",
        "#Converted_Family_Sizefor the the correlation matrix will be represented by the variable corrM_CFS\n",
        "\n",
        "\n",
        "all_data = pd.concat([all_data, Converted_Sex_Numeric], axis=1)\n",
        "all_data = pd.concat([all_data, Converted_Family_Size], axis=1)\n",
        "\n",
        "Correlation_Matrix = all_data.corr()\n",
        "print(Correlation_Matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 PassengerId  ...  Family_Size\n",
            "PassengerId                         1.000000  ...    -0.031437\n",
            "Survived                           -0.005007  ...     0.016639\n",
            "Pclass                             -0.038354  ...     0.050027\n",
            "Age                                 0.020478  ...    -0.207570\n",
            "SibSp                              -0.055224  ...     0.861952\n",
            "Parch                               0.008942  ...     0.792296\n",
            "Fare                                0.031029  ...     0.226653\n",
            "Family_Size                        -0.031437  ...     1.000000\n",
            "Sex_Numeric                         0.013406  ...    -0.188583\n",
            "Embarked_C                          0.048101  ...    -0.036553\n",
            "Embarked_Q                          0.011585  ...    -0.087190\n",
            "Embarked_S                         -0.049836  ...     0.087771\n",
            "Fare_Category_(-0.001, 7.854]       0.048268  ...    -0.252406\n",
            "Fare_Category_(10.5, 21.558]       -0.001128  ...     0.009273\n",
            "Fare_Category_(21.558, 41.579]     -0.014435  ...     0.235118\n",
            "Fare_Category_(41.579, 512.329]     0.021562  ...     0.245992\n",
            "Fare_Category_(7.854, 10.5]        -0.055563  ...    -0.235642\n",
            "Age_Category_(-0.08, 16.0]         -0.046825  ...     0.386151\n",
            "Age_Category_(16.0, 32.0]           0.040743  ...    -0.185136\n",
            "Age_Category_(32.0, 48.0]          -0.020099  ...    -0.044228\n",
            "Age_Category_(48.0, 64.0]           0.024989  ...    -0.013606\n",
            "Age_Category_(64.0, 80.0]          -0.043162  ...    -0.031587\n",
            "Sex_Numeric                         0.013406  ...    -0.188583\n",
            "Family_Size                        -0.031437  ...     1.000000\n",
            "\n",
            "[24 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHOJtyOpuR0O",
        "outputId": "30ec257f-75a6-4d91-8d1e-66e7ebe30b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_data.corr() < 0.05 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Fare_Category_(-0.001, 7.854]</th>\n",
              "      <th>Fare_Category_(10.5, 21.558]</th>\n",
              "      <th>Fare_Category_(21.558, 41.579]</th>\n",
              "      <th>Fare_Category_(41.579, 512.329]</th>\n",
              "      <th>Fare_Category_(7.854, 10.5]</th>\n",
              "      <th>Age_Category_(-0.08, 16.0]</th>\n",
              "      <th>Age_Category_(16.0, 32.0]</th>\n",
              "      <th>Age_Category_(32.0, 48.0]</th>\n",
              "      <th>Age_Category_(48.0, 64.0]</th>\n",
              "      <th>Age_Category_(64.0, 80.0]</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Family_Size</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked_C</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked_Q</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked_S</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare_Category_(-0.001, 7.854]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare_Category_(10.5, 21.558]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare_Category_(21.558, 41.579]</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare_Category_(41.579, 512.329]</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare_Category_(7.854, 10.5]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Category_(-0.08, 16.0]</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Category_(16.0, 32.0]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Category_(32.0, 48.0]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Category_(48.0, 64.0]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age_Category_(64.0, 80.0]</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Family_Size</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 PassengerId  ...  Family_Size\n",
              "PassengerId                            False  ...         True\n",
              "Survived                                True  ...         True\n",
              "Pclass                                  True  ...        False\n",
              "Age                                     True  ...         True\n",
              "SibSp                                   True  ...        False\n",
              "Parch                                   True  ...        False\n",
              "Fare                                    True  ...        False\n",
              "Family_Size                             True  ...        False\n",
              "Sex_Numeric                             True  ...         True\n",
              "Embarked_C                              True  ...         True\n",
              "Embarked_Q                              True  ...         True\n",
              "Embarked_S                              True  ...        False\n",
              "Fare_Category_(-0.001, 7.854]           True  ...         True\n",
              "Fare_Category_(10.5, 21.558]            True  ...         True\n",
              "Fare_Category_(21.558, 41.579]          True  ...        False\n",
              "Fare_Category_(41.579, 512.329]         True  ...        False\n",
              "Fare_Category_(7.854, 10.5]             True  ...         True\n",
              "Age_Category_(-0.08, 16.0]              True  ...        False\n",
              "Age_Category_(16.0, 32.0]               True  ...         True\n",
              "Age_Category_(32.0, 48.0]               True  ...         True\n",
              "Age_Category_(48.0, 64.0]               True  ...         True\n",
              "Age_Category_(64.0, 80.0]               True  ...         True\n",
              "Sex_Numeric                             True  ...         True\n",
              "Family_Size                             True  ...        False\n",
              "\n",
              "[24 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA0VN4aKx6hK",
        "outputId": "b6c3057f-e9d6-43e4-a13b-4b4c1f7e18af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unimportant = (Correlation_Matrix < 0.05)\n",
        "print(unimportant)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 PassengerId  ...  Family_Size\n",
            "PassengerId                            False  ...         True\n",
            "Survived                                True  ...         True\n",
            "Pclass                                  True  ...        False\n",
            "Age                                     True  ...         True\n",
            "SibSp                                   True  ...        False\n",
            "Parch                                   True  ...        False\n",
            "Fare                                    True  ...        False\n",
            "Family_Size                             True  ...        False\n",
            "Sex_Numeric                             True  ...         True\n",
            "Embarked_C                              True  ...         True\n",
            "Embarked_Q                              True  ...         True\n",
            "Embarked_S                              True  ...        False\n",
            "Fare_Category_(-0.001, 7.854]           True  ...         True\n",
            "Fare_Category_(10.5, 21.558]            True  ...         True\n",
            "Fare_Category_(21.558, 41.579]          True  ...        False\n",
            "Fare_Category_(41.579, 512.329]         True  ...        False\n",
            "Fare_Category_(7.854, 10.5]             True  ...         True\n",
            "Age_Category_(-0.08, 16.0]              True  ...        False\n",
            "Age_Category_(16.0, 32.0]               True  ...         True\n",
            "Age_Category_(32.0, 48.0]               True  ...         True\n",
            "Age_Category_(48.0, 64.0]               True  ...         True\n",
            "Age_Category_(64.0, 80.0]               True  ...         True\n",
            "Sex_Numeric                             True  ...         True\n",
            "Family_Size                             True  ...        False\n",
            "\n",
            "[24 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ciB4diY0XlJ"
      },
      "source": [
        "### 5) c) Based on the correlation matrix results, identify some of the features as unimportant and drop them and assign the remaining DataFrame to the variable named 'important_data'. When you drop features, leave at least 10 columns besides 'Survivided' in the 'important_data' DataFrame. After that, check the correlation to 'Survived' as you did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4tVT3qYlgVR"
      },
      "source": [
        "all_data.drop(columns=['SibSp','Parch', 'Embarked'], inplace=True)\n",
        "important_data = all_data \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6HDzJ9yAu2s",
        "outputId": "14e116c0-d85a-4f92-d487-caa0dcbb5199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "important_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Fare_Category</th>\n",
              "      <th>Age_Category</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Fare_Category_(-0.001, 7.854]</th>\n",
              "      <th>Fare_Category_(10.5, 21.558]</th>\n",
              "      <th>Fare_Category_(21.558, 41.579]</th>\n",
              "      <th>Fare_Category_(41.579, 512.329]</th>\n",
              "      <th>Fare_Category_(7.854, 10.5]</th>\n",
              "      <th>Age_Category_(-0.08, 16.0]</th>\n",
              "      <th>Age_Category_(16.0, 32.0]</th>\n",
              "      <th>Age_Category_(32.0, 48.0]</th>\n",
              "      <th>Age_Category_(48.0, 64.0]</th>\n",
              "      <th>Age_Category_(64.0, 80.0]</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NA</td>\n",
              "      <td>2</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>2</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>2</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1304</th>\n",
              "      <td>1305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1305</th>\n",
              "      <td>1306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>1</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306</th>\n",
              "      <td>1307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>1308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308</th>\n",
              "      <td>1309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NA</td>\n",
              "      <td>3</td>\n",
              "      <td>(21.558, 41.579]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1309 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      PassengerId  Survived  ...  Sex_Numeric Family_Size\n",
              "0               1       0.0  ...          1.0         2.0\n",
              "1               2       1.0  ...          0.0         2.0\n",
              "2               3       1.0  ...          0.0         1.0\n",
              "3               4       1.0  ...          0.0         2.0\n",
              "4               5       0.0  ...          1.0         1.0\n",
              "...           ...       ...  ...          ...         ...\n",
              "1304         1305       NaN  ...          1.0         1.0\n",
              "1305         1306       NaN  ...          0.0         1.0\n",
              "1306         1307       NaN  ...          1.0         1.0\n",
              "1307         1308       NaN  ...          1.0         1.0\n",
              "1308         1309       NaN  ...          1.0         3.0\n",
              "\n",
              "[1309 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKfbrCDGDh9y",
        "outputId": "dc9402fc-da6f-4bce-aa49-f291613c34c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corr_important_matrix = important_data.corr()\n",
        "corr_important_matrix[\"Survived\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived                           1.000000\n",
              "Fare_Category_(41.579, 512.329]    0.263007\n",
              "Fare                               0.257307\n",
              "Embarked_C                         0.168240\n",
              "Age_Category_(-0.08, 16.0]         0.121485\n",
              "Fare_Category_(21.558, 41.579]     0.062529\n",
              "Fare_Category_(10.5, 21.558]       0.043153\n",
              "Age_Category_(32.0, 48.0]          0.032801\n",
              "Age_Category_(48.0, 64.0]          0.030350\n",
              "Family_Size                        0.016639\n",
              "Family_Size                        0.016639\n",
              "Embarked_Q                         0.003650\n",
              "PassengerId                       -0.005007\n",
              "Age                               -0.058635\n",
              "Age_Category_(64.0, 80.0]         -0.067344\n",
              "Age_Category_(16.0, 32.0]         -0.106821\n",
              "Embarked_S                        -0.149683\n",
              "Fare_Category_(-0.001, 7.854]     -0.171109\n",
              "Fare_Category_(7.854, 10.5]       -0.191707\n",
              "Pclass                            -0.338481\n",
              "Sex_Numeric                       -0.543351\n",
              "Sex_Numeric                       -0.543351\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_btsihESme0v"
      },
      "source": [
        "### 5) d) Create X_train, Y_train and X_test DataFrames. Note that X_train should 891 instances and the rest should go to X_test. Drop the 'Survived' from X_test. Check the X_train, X_test and Y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHt8_9x1lj0e"
      },
      "source": [
        "X_train = all_data[0:891]\n",
        "X_test = all_data[891:1309]\n",
        "\n",
        "Updated_X_train = X_train.drop('Survived', axis =1)\n",
        "Y_train = X_train['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LoYqPQrHSYf",
        "outputId": "f40097cf-ddfa-4a14-b93f-306b8f9c71d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "source": [
        "Updated_X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Fare_Category</th>\n",
              "      <th>Age_Category</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Fare_Category_(-0.001, 7.854]</th>\n",
              "      <th>Fare_Category_(10.5, 21.558]</th>\n",
              "      <th>Fare_Category_(21.558, 41.579]</th>\n",
              "      <th>Fare_Category_(41.579, 512.329]</th>\n",
              "      <th>Fare_Category_(7.854, 10.5]</th>\n",
              "      <th>Age_Category_(-0.08, 16.0]</th>\n",
              "      <th>Age_Category_(16.0, 32.0]</th>\n",
              "      <th>Age_Category_(32.0, 48.0]</th>\n",
              "      <th>Age_Category_(48.0, 64.0]</th>\n",
              "      <th>Age_Category_(64.0, 80.0]</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NA</td>\n",
              "      <td>2</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>2</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>2</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(10.5, 21.558]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>1</td>\n",
              "      <td>(21.558, 41.579]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NA</td>\n",
              "      <td>4</td>\n",
              "      <td>(21.558, 41.579]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>1</td>\n",
              "      <td>(21.558, 41.579]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  ... Sex_Numeric Family_Size\n",
              "0              1       3  ...         1.0         2.0\n",
              "1              2       1  ...         0.0         2.0\n",
              "2              3       3  ...         0.0         1.0\n",
              "3              4       1  ...         0.0         2.0\n",
              "4              5       3  ...         1.0         1.0\n",
              "..           ...     ...  ...         ...         ...\n",
              "886          887       2  ...         1.0         1.0\n",
              "887          888       1  ...         0.0         1.0\n",
              "888          889       3  ...         0.0         4.0\n",
              "889          890       1  ...         1.0         1.0\n",
              "890          891       3  ...         1.0         1.0\n",
              "\n",
              "[891 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvewGoCEHVSf",
        "outputId": "375a39f3-9400-4920-a392-8a311083eebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Fare_Category</th>\n",
              "      <th>Age_Category</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Fare_Category_(-0.001, 7.854]</th>\n",
              "      <th>Fare_Category_(10.5, 21.558]</th>\n",
              "      <th>Fare_Category_(21.558, 41.579]</th>\n",
              "      <th>Fare_Category_(41.579, 512.329]</th>\n",
              "      <th>Fare_Category_(7.854, 10.5]</th>\n",
              "      <th>Age_Category_(-0.08, 16.0]</th>\n",
              "      <th>Age_Category_(16.0, 32.0]</th>\n",
              "      <th>Age_Category_(32.0, 48.0]</th>\n",
              "      <th>Age_Category_(48.0, 64.0]</th>\n",
              "      <th>Age_Category_(64.0, 80.0]</th>\n",
              "      <th>Sex_Numeric</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>892</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NA</td>\n",
              "      <td>2</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>894</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(48.0, 64.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NA</td>\n",
              "      <td>3</td>\n",
              "      <td>(10.5, 21.558]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1304</th>\n",
              "      <td>1305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1305</th>\n",
              "      <td>1306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>1</td>\n",
              "      <td>(41.579, 512.329]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306</th>\n",
              "      <td>1307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(-0.001, 7.854]</td>\n",
              "      <td>(32.0, 48.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>1308</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NA</td>\n",
              "      <td>1</td>\n",
              "      <td>(7.854, 10.5]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308</th>\n",
              "      <td>1309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NA</td>\n",
              "      <td>3</td>\n",
              "      <td>(21.558, 41.579]</td>\n",
              "      <td>(16.0, 32.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      PassengerId  Survived  ...  Sex_Numeric Family_Size\n",
              "891           892       NaN  ...          1.0         1.0\n",
              "892           893       NaN  ...          0.0         2.0\n",
              "893           894       NaN  ...          1.0         1.0\n",
              "894           895       NaN  ...          1.0         1.0\n",
              "895           896       NaN  ...          0.0         3.0\n",
              "...           ...       ...  ...          ...         ...\n",
              "1304         1305       NaN  ...          1.0         1.0\n",
              "1305         1306       NaN  ...          0.0         1.0\n",
              "1306         1307       NaN  ...          1.0         1.0\n",
              "1307         1308       NaN  ...          1.0         1.0\n",
              "1308         1309       NaN  ...          1.0         3.0\n",
              "\n",
              "[418 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzGEddHeHXeE",
        "outputId": "44fb70e8-848e-4ca8-c387-a8550454a3ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      0.0\n",
              "      ... \n",
              "886    0.0\n",
              "887    1.0\n",
              "888    0.0\n",
              "889    1.0\n",
              "890    0.0\n",
              "Name: Survived, Length: 891, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL3RjPMd5TbF"
      },
      "source": [
        "### 5) e) Use StandardScaler of Scikit Learn to scale the 'Fare' feature of both X_train and X_test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDkSrDqllnPE",
        "outputId": "b8d44b24-e9e4-4b2e-ff98-c33002ae326d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "Fare_train = np.array((X_train['Fare']))\n",
        "Fare_test = np.array((X_test['Fare']))\n",
        "\n",
        "Update_X_train = Fare_train.reshape(1,-1)\n",
        "Update_X_test = Fare_test.reshape(1,-1)\n",
        "\n",
        "print(scaler.fit(Fare_train))\n",
        "print(scaler.fit(Fare_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f4e74b101cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mUpdate_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFare_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFare_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFare_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  7.25    71.2833   7.925   53.1      8.05     8.4583  51.8625  21.075\n  11.1333  30.0708  16.7     26.55     8.05    31.275    7.8542  16.\n  29.125   13.      18.       7.225   26.      13.       8.0292  35.5\n  21.075   31.3875   7.225  263.       7.8792   7.8958  27.7208 146.5208\n   7.75    10.5     82.1708  52.       7.2292   8.05    18.      11.2417\n   9.475   21.       7.8958  41.5792   7.8792   8.05    15.5      7.75\n  21.6792  17.8     39.6875   7.8     76.7292  26.      61.9792  35.5\n  10.5      7.2292  27.75    46.9      7.2292  80.      83.475   27.9\n  27.7208  15.2458  10.5      8.1583   7.925    8.6625  10.5     46.9\n  73.5     14.4542  56.4958   7.65     7.8958   8.05    29.      12.475\n   9.       9.5      7.7875  47.1     10.5     15.85    34.375    8.05\n 263.       8.05     8.05     7.8542  61.175   20.575    7.25     8.05\n  34.6542  63.3583  23.      26.       7.8958   7.8958  77.2875   8.6542\n   7.925    7.8958   7.65     7.775    7.8958  24.15    52.      14.4542\n   8.05     9.825   14.4583   7.925    7.75    21.     247.5208  31.275\n  73.5      8.05    30.0708  13.      77.2875  11.2417   7.75     7.1417\n  22.3583   6.975    7.8958   7.05    14.5     26.      13.      15.0458\n  26.2833  53.1      9.2167  79.2     15.2458   7.75    15.85     6.75\n  11.5     36.75     7.7958  34.375   26.      13.      12.525   66.6\n   8.05    14.5      7.3125  61.3792   7.7333   8.05     8.6625  69.55\n  16.1     15.75     7.775    8.6625  39.6875  20.525   55.      27.9\n  25.925   56.4958  33.5     29.125   11.1333   7.925   30.6958   7.8542\n  25.4667  28.7125  13.       0.      69.55    15.05    31.3875  39.\n  22.025   50.      15.5     26.55    15.5      7.8958  13.      13.\n   7.8542  26.      27.7208 146.5208   7.75     8.4042   7.75    13.\n   9.5     69.55     6.4958   7.225    8.05    10.4625  15.85    18.7875\n   7.75    31.       7.05    21.       7.25    13.       7.75   113.275\n   7.925   27.      76.2917  10.5      8.05    13.       8.05     7.8958\n  90.       9.35    10.5      7.25    13.      25.4667  83.475    7.775\n  13.5     31.3875  10.5      7.55    26.      26.25    10.5     12.275\n  14.4542  15.5     10.5      7.125    7.225   90.       7.775   14.5\n  52.5542  26.       7.25    10.4625  26.55    16.1     20.2125  15.2458\n  79.2     86.5    512.3292  26.       7.75    31.3875  79.65     0.\n   7.75    10.5     39.6875   7.775  153.4625 135.6333  31.       0.\n  19.5     29.7      7.75    77.9583   7.75     0.      29.125   20.25\n   7.75     7.8542   9.5      8.05    26.       8.6625   9.5      7.8958\n  13.       7.75    78.85    91.0792  12.875    8.85     7.8958  27.7208\n   7.2292 151.55    30.5    247.5208   7.75    23.25     0.      12.35\n   8.05   151.55   110.8833 108.9     24.      56.9292  83.1583 262.375\n  26.       7.8958  26.25     7.8542  26.      14.     164.8667 134.5\n   7.25     7.8958  12.35    29.      69.55   135.6333   6.2375  13.\n  20.525   57.9792  23.25    28.5    153.4625  18.     133.65     7.8958\n  66.6    134.5      8.05    35.5     26.     263.      13.      13.\n  13.      13.      13.      16.1     15.9      8.6625   9.225   35.\n   7.2292  17.8      7.225    9.5     55.      13.       7.8792   7.8792\n  27.9     27.7208  14.4542   7.05    15.5      7.25    75.25     7.2292\n   7.75    69.3     55.4417   6.4958   8.05   135.6333  21.075   82.1708\n   7.25   211.5      4.0125   7.775  227.525   15.7417   7.925   52.\n   7.8958  73.5     46.9     13.       7.7292  12.     120.       7.7958\n   7.925  113.275   16.7      7.7958   7.8542  26.      10.5     12.65\n   7.925    8.05     9.825   15.85     8.6625  21.       7.75    18.75\n   7.775   25.4667   7.8958   6.8583  90.       0.       7.925    8.05\n  32.5     13.      13.      24.15     7.8958   7.7333   7.875   14.4\n  20.2125   7.25    26.      26.       7.75     8.05    26.55    16.1\n  26.       7.125   55.9    120.      34.375   18.75   263.      10.5\n  26.25     9.5      7.775   13.       8.1125  81.8583  19.5     26.55\n  19.2583  30.5     27.75    19.9667  27.75    89.1042   8.05     7.8958\n  26.55    51.8625  10.5      7.75    26.55     8.05    38.5     13.\n   8.05     7.05     0.      26.55     7.725   19.2583   7.25     8.6625\n  27.75    13.7917   9.8375  52.      21.       7.0458   7.5208  12.2875\n  46.9      0.       8.05     9.5875  91.0792  25.4667  90.      29.7\n   8.05    15.9     19.9667   7.25    30.5     49.5042   8.05    14.4583\n  78.2667  15.1    151.55     7.7958   8.6625   7.75     7.6292   9.5875\n  86.5    108.9     26.      26.55    22.525   56.4958   7.75     8.05\n  26.2875  59.4      7.4958  34.0208  10.5     24.15    26.       7.8958\n  93.5      7.8958   7.225   57.9792   7.2292   7.75    10.5    221.7792\n   7.925   11.5     26.       7.2292   7.2292  22.3583   8.6625  26.25\n  26.55   106.425   14.5     49.5     71.      31.275   31.275   26.\n 106.425   26.      26.      13.8625  20.525   36.75   110.8833  26.\n   7.8292   7.225    7.775   26.55    39.6    227.525   79.65    17.4\n   7.75     7.8958  13.5      8.05     8.05    24.15     7.8958  21.075\n   7.2292   7.8542  10.5     51.4792  26.3875   7.75     8.05    14.5\n  13.      55.9     14.4583   7.925   30.     110.8833  26.      40.125\n   8.7125  79.65    15.      79.2      8.05     8.05     7.125   78.2667\n   7.25     7.75    26.      24.15    33.       0.       7.225   56.9292\n  27.       7.8958  42.4      8.05    26.55    15.55     7.8958  30.5\n  41.5792 153.4625  31.275    7.05    15.5      7.75     8.05    65.\n  14.4     16.1     39.      10.5     14.4542  52.5542  15.7417   7.8542\n  16.1     32.3208  12.35    77.9583   7.8958   7.7333  30.       7.0542\n  30.5      0.      27.9     13.       7.925   26.25    39.6875  16.1\n   7.8542  69.3     27.9     56.4958  19.2583  76.7292   7.8958  35.5\n   7.55     7.55     7.8958  23.       8.4333   7.8292   6.75    73.5\n   7.8958  15.5     13.     113.275  133.65     7.225   25.5875   7.4958\n   7.925   73.5     13.       7.775    8.05    52.      39.      52.\n  10.5     13.       0.       7.775    8.05     9.8417  46.9    512.3292\n   8.1375  76.7292   9.225   46.9     39.      41.5792  39.6875  10.1708\n   7.7958 211.3375  57.      13.4167  56.4958   7.225   26.55    13.5\n   8.05     7.7333 110.8833   7.65   227.525   26.2875  14.4542   7.7417\n   7.8542  26.      13.5     26.2875 151.55    15.2458  49.5042  26.55\n  52.       9.4833  13.       7.65   227.525   10.5     15.5      7.775\n  33.       7.0542  13.      13.      53.1      8.6625  21.       7.7375\n  26.       7.925  211.3375  18.7875   0.      13.      13.      16.1\n  34.375  512.3292   7.8958   7.8958  30.      78.85   262.375   16.1\n   7.925   71.      20.25    13.      53.1      7.75    23.      12.475\n   9.5      7.8958  65.      14.5      7.7958  11.5      8.05    86.5\n  14.5      7.125    7.2292 120.       7.775   77.9583  39.6      7.75\n  24.15     8.3625   9.5      7.8542  10.5      7.225   23.       7.75\n   7.75    12.475    7.7375 211.3375   7.2292  57.      30.      23.45\n   7.05     7.25     7.4958  29.125   20.575   79.2      7.75    26.\n  69.55    30.6958   7.8958  13.      25.9292   8.6833   7.2292  24.15\n  13.      26.25   120.       8.5167   6.975    7.775    0.       7.775\n  13.      53.1      7.8875  24.15    10.5     31.275    8.05     0.\n   7.925   37.0042   6.45    27.9     93.5      8.6625   0.      12.475\n  39.6875   6.95    56.4958  37.0042   7.75    80.      14.4542  18.75\n   7.2292   7.8542   8.3     83.1583   8.6625   8.05    56.4958  29.7\n   7.925   10.5     31.       6.4375   8.6625   7.55    69.55     7.8958\n  33.      89.1042  31.275    7.775   15.2458  39.4     26.       9.35\n 164.8667  26.55    19.2583   7.2292  14.1083  11.5     25.9292  69.55\n  13.      13.      13.8583  50.4958   9.5     11.1333   7.8958  52.5542\n   5.       9.      24.       7.225    9.8458   7.8958   7.8958  83.1583\n  26.       7.8958  10.5167  10.5      7.05    29.125   13.      30.\n  23.45    30.       7.75  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV8Z1FdiBXcf"
      },
      "source": [
        "### 5) f) For each of the algorithms, use Scikit-Learn's cross-validation feature to measure the performance and print out mean and std for each algoritm:\n",
        "\n",
        "1. Stochastic Gradient Descent (SGD)\n",
        "2. LogisticRegression\n",
        "3. Support Vector Machine (kernel='linear' parameter)\n",
        "4. Support Vector Machine (kernel = 'rbf' parameter)\n",
        "5. DecisionTreeClassifier\n",
        "6. RandomForestClassifier\n",
        "7. ExtraTreesClassifier\n",
        "8. AdaBoostClassifier\n",
        "9. GradientBoostingClassifier\n",
        "10. XGBoost\n",
        "-- You can import XGBoost library as follows:  \"from xgboost import XGBClassifier\"\n",
        "\n",
        "Parameters:\n",
        "- Set the scoring parameter of cross-validation to 'f1'\n",
        "- Use the default cv = 5 parameter of cross-validation\n",
        "- Use random_state = 42 for initializing model algorithms\n",
        "- Use the kernel parameter indicated above for SVM algorithms\n",
        "- For others, use the default parameters (no need to specify explicitly)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRQFbT2-7Kp1",
        "outputId": "b3321fee-8cb9-4ae2-d5d9-92376cf01f87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import label encoder \n",
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Name attribute. \n",
        "Updated_X_train['Name']= label_encoder.fit_transform(Updated_X_train['Name']) \n",
        "  \n",
        "Updated_X_train['Name'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([108, 190, 353, 272,  15, 554, 515, 624, 412, 576, 727,  95, 729,\n",
              "        28, 840, 359, 682, 867, 839, 512, 273,  80, 523, 765, 626,  44,\n",
              "       240, 260, 605, 813, 828, 776, 289, 856, 535, 372, 505, 134, 837,\n",
              "       589,   7, 827, 446, 456, 212, 697, 473, 604, 726,  38, 629, 594,\n",
              "       333, 246, 620, 873, 707, 595, 853, 299, 749, 385, 337, 755, 784,\n",
              "       560, 596, 185,  25, 440, 396, 300, 376, 161,  87, 546, 778, 563,\n",
              "       127, 223, 842, 737, 519, 141, 386,  52, 255, 764, 259, 149, 159,\n",
              "        31, 150, 209, 184, 740, 292, 308, 219, 422, 656, 658, 858, 405,\n",
              "       312, 542, 724, 559, 675, 552, 667, 882,  67, 417,  46, 645, 178,\n",
              "       826,  70,  24, 362, 551, 575, 848, 857, 588, 525, 499, 653, 234,\n",
              "       225, 165, 695, 851, 772, 685, 585, 271, 618, 282,  99, 597, 319,\n",
              "       116,  32, 586,  29, 254, 580, 121,  68, 643, 532, 889, 612, 866,\n",
              "       287, 181, 767, 716, 186, 847,  82, 129, 628, 293, 157, 760,  69,\n",
              "       486, 832, 680, 408, 752, 769, 444, 464, 388, 320, 474, 717, 650,\n",
              "        41,  76, 441, 700, 601, 698, 101, 823, 664, 136,  20, 579, 113,\n",
              "       495, 533, 611, 497, 881, 834, 721, 403, 878, 166, 789,  51,   9,\n",
              "       140,  94,  12, 131, 649, 288, 437, 582, 375, 390,  72, 338, 791,\n",
              "       105, 306, 581, 379,  83, 531, 492, 243, 467, 339, 460, 754,  43,\n",
              "       479, 329, 370, 172, 648, 383, 883, 567, 169, 500,  47, 539, 481,\n",
              "       322,  78, 147, 673, 790, 782, 487, 702, 819, 808, 156, 844, 636,\n",
              "       771,  42, 799, 340, 356, 674, 631, 652, 305,  91, 125, 817, 530,\n",
              "       577, 350,  33, 482, 634, 681,   2, 227, 614, 887, 221, 770, 779,\n",
              "       886, 570, 378, 177,  65,  90, 477, 315, 541, 478, 324,  17, 714,\n",
              "        71, 431, 518, 411, 428, 868,  16, 248, 647,   3, 263, 348, 710,\n",
              "       449, 355, 342, 590, 423, 555, 859, 775, 211, 200, 762, 128, 722,\n",
              "       877, 598,  60, 295, 363, 517, 637, 304, 838, 265, 210, 642, 117,\n",
              "       192,  93, 578, 258, 170, 733, 262, 111, 768, 207, 183, 215, 608,\n",
              "       870, 237,  37, 879, 835, 104, 270, 522, 545, 759, 888,  64,  40,\n",
              "       599,   5, 845, 562, 400,  48, 328, 863,  75, 690, 625, 536, 454,\n",
              "       862,  85, 314,  86, 572, 811, 373, 665, 205, 298, 118, 715, 468,\n",
              "       144, 393, 313, 583, 728, 404, 613, 524, 623, 821, 592,   6, 418,\n",
              "       318, 616, 274, 861, 687,  88, 465, 732, 343, 540, 191, 792, 528,\n",
              "       226, 742, 513, 829, 281, 155, 884, 198, 701, 872, 162, 662, 249,\n",
              "       663,  92, 810, 491, 420, 744, 143, 253, 688, 261, 447, 344, 323,\n",
              "       659, 679, 402, 216, 529, 735,  55, 661, 854, 316, 257, 290, 644,\n",
              "       392, 537, 436, 815, 603,  21, 557, 280, 538, 502, 296, 132, 766,\n",
              "       731,  54, 430, 124, 855, 401, 787, 164, 676, 107, 425, 365, 297,\n",
              "       268, 706, 825,  89, 466, 381, 435, 774, 182, 317, 871, 547,  39,\n",
              "       781, 880, 242, 738,  18, 796, 130, 133, 607, 450, 501, 646, 670,\n",
              "       106, 610, 455, 195, 849, 521, 705, 168, 843, 472, 709,  35, 641,\n",
              "       651, 841, 448, 364, 427, 244, 689, 245, 725, 366, 669, 818, 236,\n",
              "       654, 123, 341, 120, 461, 692, 266, 188,  26,  27,  73, 222, 587,\n",
              "        74, 622, 294, 203, 804, 736, 600, 463, 609, 874, 228, 693, 800,\n",
              "       885, 558, 751, 593, 746, 527, 204, 786, 627, 217, 416, 336,  36,\n",
              "       251, 432, 708, 639, 277, 745, 135, 419, 160, 805, 224, 703, 640,\n",
              "       798, 395, 267, 284, 566, 691, 783, 238, 100, 154, 830, 470, 409,\n",
              "        98, 229, 391, 761, 335, 816, 374, 483, 424, 199, 458, 741,  30,\n",
              "       394, 568, 377, 110, 357, 197, 488,  77, 279, 875, 439, 573, 327,\n",
              "       103, 794, 442, 490,  96, 602,  66, 494, 777, 635, 757, 206, 469,\n",
              "       173, 633, 809, 397, 723, 758, 252,  53, 332, 180, 747, 865, 780,\n",
              "       544, 218, 421, 606, 352, 360, 671, 102, 232, 584, 264,  57, 171,\n",
              "       167, 484, 361, 119, 699, 179, 802, 114, 202, 543, 864, 846, 231,\n",
              "       730, 824, 302, 137, 655, 345, 615, 301, 112, 457, 632, 194, 247,\n",
              "       498, 213, 426, 452, 713, 850, 153, 433, 565, 803, 382,  45, 743,\n",
              "        63, 275, 326, 556, 434, 126, 163, 561, 514, 443, 801, 459, 307,\n",
              "       773, 241, 822, 520, 410, 331, 399, 286, 368, 151, 617, 677, 507,\n",
              "       115, 387,  14, 346, 445,  84, 820, 869, 256, 476, 389, 574, 347,\n",
              "       148, 711, 526, 788, 187,   1, 748, 511, 176, 852, 549, 833, 415,\n",
              "       358, 321, 138,  58, 806, 704, 276, 591,  62, 146, 233, 369, 109,\n",
              "       506, 553, 309, 480, 398, 496, 235, 367, 569, 812, 239, 438, 694,\n",
              "        50, 214, 489, 414,  13, 330, 753, 683, 208, 310, 429, 278, 719,\n",
              "       380, 201, 621, 462, 619, 384, 831, 666, 174, 142, 807, 351, 406,\n",
              "        34, 660, 534, 152,  10, 475, 763,  23, 814, 269, 354, 504, 371,\n",
              "       756, 349, 493, 678, 550, 630, 250, 453, 503, 516, 785, 876, 686,\n",
              "       712,  49,  19, 175, 638, 750, 158, 508,  11, 564, 734, 471, 189,\n",
              "         0, 720, 509, 334, 291,  22, 795,  97, 485, 145,   8, 860, 196,\n",
              "        56, 672, 325, 283, 797, 718, 285, 122, 230, 696, 890, 407,  59,\n",
              "        79, 139, 836,   4, 571, 311, 657, 451, 668, 739, 510, 193,  61,\n",
              "       793, 684, 548, 303, 413,  81, 220])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgU3TulGprCd",
        "outputId": "25db4d38-72d3-4afd-b752-d8f4a09767a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import label encoder \n",
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Sex attribute. \n",
        "Updated_X_train['Sex']= label_encoder.fit_transform(Updated_X_train['Sex']) \n",
        "  \n",
        "Updated_X_train['Sex'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnR4SwJQAwe5",
        "outputId": "cb6cf2ec-e77d-40e4-a121-47e41bb66910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import label encoder \n",
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Ticket attribute. \n",
        "Updated_X_train['Ticket']= label_encoder.fit_transform(Updated_X_train['Ticket']) \n",
        "  \n",
        "Updated_X_train['Ticket'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([523, 596, 669,  49, 472, 275,  85, 395, 344, 132, 616,  38, 535,\n",
              "       333, 413, 153, 480, 151, 301, 184, 139, 152, 278,  42, 329, 179,\n",
              "        95, 283, 362, 598, 586, 288, 549, 600,  43, 202, 514, 302, 186,\n",
              "       507,  53, 391, 634, 282, 617, 462,  76, 190, 377, 249, 522, 587,\n",
              "       239,  29,  94, 555, 215, 561, 566, 197,  32, 457, 337, 601, 189,\n",
              "       553, 623, 248, 270, 557, 621, 204,  80, 347, 355, 473, 158, 432,\n",
              "       304, 311, 280,  25, 637, 247, 676, 652, 297, 298, 341, 678, 548,\n",
              "       428, 475, 607, 612, 117, 150, 384, 361, 417, 505, 245, 354, 296,\n",
              "       254, 388, 469,   2, 193, 274, 491, 176, 666, 460, 585, 540, 219,\n",
              "       463, 541, 196, 318, 380, 640, 537, 111, 552, 630,  55, 504, 592,\n",
              "       203, 332, 668, 438, 118, 558, 405, 113, 147, 622,  36, 516, 538,\n",
              "       573, 595, 418, 654, 258, 568, 470, 559, 323, 265, 423,  28, 576,\n",
              "         5, 659,  90, 412, 488, 593, 169, 574, 629, 114, 271,  34, 459,\n",
              "        11, 435, 386, 122, 227, 406, 604, 452, 494, 461, 160, 306, 242,\n",
              "       177, 530, 316, 216, 445,  17, 642, 570, 526, 163, 443, 416, 670,\n",
              "       142,  63, 679, 653, 105, 102, 375,  93, 615, 672, 525, 125, 322,\n",
              "       128, 554, 677, 198, 556, 231, 636, 444, 674, 658, 213,  92, 325,\n",
              "       166,  54, 144, 422,  31, 536, 458, 185, 589,   0, 608, 115, 482,\n",
              "         1,  16, 478, 546, 334, 588, 613,  47, 162, 594, 465,  71, 326,\n",
              "       135, 551, 290, 340, 310, 533,  24, 378, 308, 353, 134, 464,  91,\n",
              "        64, 635, 376, 374, 606, 212,  37,  98, 513, 441, 109, 527,  83,\n",
              "       611, 575, 584,  59, 602, 167, 382, 571, 343, 232, 453,  81, 524,\n",
              "       365, 124, 299, 229,   7,  20, 605, 370, 510,  39, 159, 149, 112,\n",
              "       157, 257, 483, 562, 262, 503,  30, 214, 182, 314, 131, 279, 285,\n",
              "       633, 211, 641, 544,   4, 175,  78, 581,  58, 244, 273, 545,  27,\n",
              "       183, 324, 610, 187, 665, 371, 220, 447, 625,  33, 401, 246, 410,\n",
              "       414, 226, 146, 140, 663, 292, 492, 267, 230, 321, 237, 255, 367,\n",
              "       487, 655, 295, 224, 168, 225, 307, 392, 534, 259, 331, 521, 100,\n",
              "       170, 437, 644,   3, 476, 627, 657,  72, 547, 305, 328, 116, 499,\n",
              "       289,  45, 194,  40, 497,  22,  84, 528, 379,  73,  86, 572, 468,\n",
              "        96, 429,   6, 121, 539, 639,  44, 421, 272, 263, 628, 509, 252,\n",
              "       315, 411, 251, 136, 531, 489,  61, 517, 498, 649,  41, 603, 518,\n",
              "       454, 564, 402, 261, 433, 276, 490, 180,  10, 542, 479, 648, 577,\n",
              "       599, 356, 456, 560, 110, 381,  67, 390, 173, 217, 446, 673, 583,\n",
              "       250, 235, 181, 210, 260,  21, 614, 426,  75, 680, 233, 501, 631,\n",
              "       148, 284, 171, 335,  52,  57, 300, 471, 389, 103, 651, 645, 519,\n",
              "       352, 207, 415, 624,  60, 578,  77, 520, 420, 143, 209, 661, 133,\n",
              "        68, 291, 129,  74,  79, 515, 656, 532, 434, 626, 155, 192, 360,\n",
              "        46, 430,   9, 396, 385,  50, 638, 467, 431, 106, 253, 188,  56,\n",
              "       400, 495, 455, 104, 369, 286, 218, 345,  70,  13, 130, 664, 409,\n",
              "       373,  69, 620, 567, 366, 512, 277, 439, 368, 241, 172, 496, 357,\n",
              "       660, 123, 256, 529,  99, 240, 569, 550, 145, 138, 397, 294, 493,\n",
              "       281, 500, 372, 403, 141,  89, 393, 200,  48, 156, 425, 419, 346,\n",
              "       579, 449, 398, 108, 580, 582,  19, 506, 164, 348, 293, 440, 319,\n",
              "       408,  65, 161,  51, 266, 451, 127, 667, 137, 228, 119, 349, 364,\n",
              "        82, 477, 662, 165,  35, 287, 234, 486, 312, 351, 404, 238, 424,\n",
              "       646, 191, 327,  18, 436, 511, 313, 407, 619, 201, 236, 330, 481,\n",
              "       450, 208,  26, 675, 643, 474, 243,  66, 597, 350, 223,  87, 383,\n",
              "       206, 174, 338, 320,  12, 336, 154, 339, 222, 427,  15, 671, 618,\n",
              "       543, 269,  97, 448, 442, 199, 342, 107, 609, 268, 485,  62, 647,\n",
              "       205, 264, 563, 359, 317, 591, 484,  23, 178, 399, 221,  88, 120,\n",
              "       126, 632, 590, 309, 387, 502, 303, 195, 358, 363, 394, 508, 565,\n",
              "       650, 101,  14,   8, 466])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukcCzlAhBTmO",
        "outputId": "7c261c20-914f-405b-8b4d-64ac8f1a9c9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import label encoder \n",
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Cabin attribute. \n",
        "Updated_X_train['Cabin']= label_encoder.fit_transform(Updated_X_train['Cabin']) \n",
        "  \n",
        "Updated_X_train['Cabin'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([146,  81,  55, 129, 145,  49, 111,  13,  63,  41, 101,  23,  71,\n",
              "        21,  80, 142, 140, 122,  12,  91,  98,  52,  36, 116, 138, 107,\n",
              "        45, 141,  61, 123,  18,  14,  69, 144,   9,  28,  43,   8, 103,\n",
              "        93,  87,  78, 102,  83,  40, 134,  46,  57,  89,  54, 113,   3,\n",
              "        31,  90,  62,  51,  74, 125,  72,  35,  76, 124,  65,  17,  56,\n",
              "        85, 127, 147,  59, 104,  24, 131,  79,  47, 115, 128,  10,  50,\n",
              "        53,  86, 126,  97, 117, 133,   1,  25,  64,  96,  42, 121, 106,\n",
              "        39,  88,  26,  27,  20,  82,  77,   2,  48,  75,   0, 135,  29,\n",
              "         4,  95, 110, 114,   5,  33,   7, 108, 132,  58,  38,  34, 109,\n",
              "        32,  19, 139,  73, 120,  84,  66, 137,  15, 105,  67, 100, 118,\n",
              "        92, 136, 143,  22, 112,  44,  94,  11,  16,  37, 130,  68,  99,\n",
              "       119,   6,  70,  30,  60])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhD7XhICDNfa",
        "outputId": "4b72cd00-3965-45a6-fe3b-bf29b81955c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Fare_Category attribute. \n",
        "Updated_X_train['Fare_Category']= label_encoder.fit_transform(Updated_X_train['Fare_Category']) \n",
        "  \n",
        "Updated_X_train['Fare_Category'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 4, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rLhKwkoDY5C",
        "outputId": "25b18740-ff56-4ed0-bc69-aef0e4441502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import preprocessing \n",
        "  \n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "  \n",
        "# Encode Age_category attribute. \n",
        "Updated_X_train['Age_Category']= label_encoder.fit_transform(Updated_X_train['Age_Category']) \n",
        "  \n",
        "Updated_X_train['Age_Category'].unique() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8APILY4A663",
        "outputId": "f7e130d9-4b4a-43f1-95e6-bb15b4757221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "encoded_feat = OneHotEncoder().fit_transform(Updated_X_train['Ticket'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)\n",
        "feat = pd.DataFrame(encoded_feat)\n",
        "feat2 = feat.drop(feat.iloc[:, 27:], inplace=True, axis=1)\n",
        "Updated_X_train = Updated_X_train.append(feat2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmO7-6Hc6ywY",
        "outputId": "45a1dc4a-6fc3-434f-f758-eed7c0df7279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "encoded_feat = OneHotEncoder().fit_transform(Updated_X_train['Cabin'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)\n",
        "feat = pd.DataFrame(encoded_feat)\n",
        "feat3 = feat.drop(feat.iloc[:, 27:], inplace=True, axis=1)\n",
        "Updated_X_train = Updated_X_train.append(feat3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Biy9hfTDmOY",
        "outputId": "82873a97-4006-4b4c-e4f2-7671ee22127b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "encoded_feat = OneHotEncoder().fit_transform(Updated_X_train['Fare_Category'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)\n",
        "feat = pd.DataFrame(encoded_feat)\n",
        "feat4 = feat.drop(feat.iloc[:, 27:], inplace=True, axis=1)\n",
        "Updated_X_train = Updated_X_train.append(feat4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcEXFsuap37Y",
        "outputId": "46a17e1e-910a-4f5e-c149-2fcc38c01684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "encoded_feat = OneHotEncoder().fit_transform(Updated_X_train['Sex'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)\n",
        "feat = pd.DataFrame(encoded_feat)\n",
        "feat6 = feat.drop(feat.iloc[:, 27:], inplace=True, axis=1)\n",
        "Updated_X_train = Updated_X_train.append(feat6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v94_SbSeDl-F",
        "outputId": "8baf299a-33b6-4bb9-e544-7f6095db8121",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "encoded_feat = OneHotEncoder().fit_transform(Updated_X_train['Age_Category'].values.reshape(-1,1)).toarray()\n",
        "print(encoded_feat)\n",
        "feat = pd.DataFrame(encoded_feat)\n",
        "feat5 = feat.drop(feat.iloc[:, 27:], inplace=True, axis=1)\n",
        "Updated_X_train = Updated_X_train.append(feat5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBvI3w8IMGy4"
      },
      "source": [
        "1. Stochastic Gradient Descent (SGD)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzGHf97hMKip",
        "outputId": "bcb97b7a-fcc5-47c2-8002-341092ba0ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "clf = make_pipeline(StandardScaler(),\n",
        "                   SGDClassifier(random_state =42))\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "\n",
        "SGDClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of SGD:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of SGD:\", round(scores.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.709 0.593 0.677 0.652 0.615]\n",
            "Mean value of SGD: 0.649\n",
            "Standard deviation value of SGD: 0.042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD9L6N2hMK-i"
      },
      "source": [
        "2. LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYn_FHpGMOcF",
        "outputId": "b1277993-f18e-43c0-980e-d6a16011294f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = LogisticRegression(random_state=42,max_iter=10000).fit(Updated_X_train, Y_train)\n",
        "LogisticRegression()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of Logistic Regression:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of Logistic Regression:\", round(scores.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.692 0.756 0.692 0.678 0.739]\n",
            "Mean value of Logistic Regression: 0.711\n",
            "Standard deviation value of Logistic Regression: 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6jX60MKse2"
      },
      "source": [
        "3.Support Vector Machine (kernel='linear' parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24eK04oJbs-",
        "outputId": "77c9a9f6-0906-4e8e-bd21-6840d169c5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "clf = make_pipeline(StandardScaler(), SVC(kernel ='linear',random_state=42))\n",
        "clf.fit(Updated_X_train,Y_train)\n",
        "SVC()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of SVM:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of SVM:\", round(scores.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.726 0.742 0.712 0.645 0.708]\n",
            "Mean value of SVM: 0.707\n",
            "Standard deviation value of SVM: 0.033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqi40bbpK6Cm"
      },
      "source": [
        "4.Support Vector Machine (kernel='rbf' parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1quFpDc8LA76",
        "outputId": "3fc3a6ac-5ff2-45ab-f865-82c2fc5ffd41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "#No need to assign kernel to 'rbf'. It is that by default.\n",
        "clf = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
        "clf.fit(Updated_X_train,Y_train)\n",
        "SVC()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of SVM:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of SVM:\", round(scores.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.754 0.763 0.742 0.701 0.785]\n",
            "Mean value of SVM: 0.749\n",
            "Standard deviation value of SVM: 0.028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOWnNr8SGCDn"
      },
      "source": [
        "5.DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtgKcldvGGso",
        "outputId": "c343c351-09a4-487f-91b7-5459c3ffe55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "DecisionTreeClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of DecisionTreeClassifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of DecisionTreeClassifier:\", round(scores.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.213 0.707 0.727 0.651 0.789]\n",
            "Mean value of DecisionTreeClassifier: 0.617\n",
            "Standard deviation value of DecisionTreeClassifier: 0.207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYZfWZzdBv9R"
      },
      "source": [
        "6.RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExL-IzeAlrAb",
        "outputId": "e77723d1-2799-48dd-f522-6e7ce1851ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "RandomForestClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train, scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of Classifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of RandomForestClassifier:\", round(scores.std(), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.736 0.752 0.8   0.732 0.8  ]\n",
            "Mean value of Classifier: 0.764\n",
            "Standard deviation value of RandomForestClassifier: 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8TaLeoPF1NA"
      },
      "source": [
        "7. ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-hmoD0NuxRd",
        "outputId": "241cfc70-d664-463f-8519-189a5986bf03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "clf = ExtraTreesClassifier(random_state=42)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "ExtraTreesClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train , scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of ExtraTreesClassifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of ExtraTreesClassifier:\", round(scores.std(), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.748 0.721 0.763 0.712 0.789]\n",
            "Mean value of ExtraTreesClassifier: 0.747\n",
            "Standard deviation value of ExtraTreesClassifier: 0.028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhDCQLwCF6nY"
      },
      "source": [
        "8.AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qWLJBaru8yG",
        "outputId": "07bf06e5-2fa8-4851-c11b-9a0f7c989ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "clf = AdaBoostClassifier(random_state=42)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "AdaBoostClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train , scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of AdaBoostClassifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of AdaBoostClassifier:\", round(scores.std(), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.    0.745 0.752 0.726 0.   ]\n",
            "Mean value of AdaBoostClassifier: 0.444\n",
            "Standard deviation value of AdaBoostClassifier: 0.363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLvKInOKFmVO"
      },
      "source": [
        "9. GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWpzCZsZvJuZ",
        "outputId": "911c8017-7614-414a-e924-2e2aa9d5c697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = GradientBoostingClassifier(random_state=42)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "GradientBoostingClassifier()\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train , scoring = 'f1', cv=5)\n",
        "\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of GradientBoostingClassifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of GradientBoostingClassifier:\", round(scores.std(), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.029 0.754 0.818 0.744 0.756]\n",
            "Mean value of GradientBoostingClassifier: 0.62\n",
            "Standard deviation value of GradientBoostingClassifier: 0.297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9SkpapBFdmE"
      },
      "source": [
        "10. XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejAN48NLT_4B",
        "outputId": "3fd47627-d48b-4650-f05c-9bd95fce120c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "Updated_X_train = np.array(Updated_X_train)\n",
        "Y_train= np.array(Y_train)\n",
        "clf = XGBClassifier()\n",
        "clf.fit(Updated_X_train,Y_train.ravel())\n",
        "\n",
        "scores = cross_val_score(clf, Updated_X_train, Y_train , scoring = 'f1', cv=5)\n",
        "print('Performance scores:', scores.round(3))\n",
        "print(\"Mean value of XGBClassifier:\", round(scores.mean(),3))\n",
        "print(\"Standard deviation value of XGBClassifier:\", round(scores.std(), 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance scores: [0.029 0.766 0.803 0.702 0.794]\n",
            "Mean value of XGBClassifier: 0.619\n",
            "Standard deviation value of XGBClassifier: 0.297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URIgcZND9pvk"
      },
      "source": [
        "### 5) g) Select the top 3 best performing classifiers. List them along with their mean and std scores. For these top 3 best performing classifiers, find the best hyperparameters using GridSearchCV. \n",
        "\n",
        "- Use estimator.get_params().keys() or the API description of the classifiers to find out which hyperparameters you can use. \n",
        "- Use the same scoring parameter ('f1') and use cv = 10 this time. \n",
        "- Print out the best_estimator_ and best_score_ results of your Grid Search\n",
        "- Use the following hyparparameter options if they fit for your top 3 classifiers:\n",
        "\n",
        "n_estimators = [300, 400, 500]\n",
        "\n",
        "learning_rate = [0.3, 0.1, 0.05]\n",
        "\n",
        "max_features =  [1, 0.5, 0.3]\n",
        "\n",
        "subsample = [1, 0.5, 0.3]\n",
        "\n",
        "max_samples = [1, 0.5, 0.3]\n",
        "\n",
        "bootstrap = [True,False]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzRb9V4FlzCP"
      },
      "source": [
        "Top 1: RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y10xaoaHlzcp",
        "outputId": "7e853a26-791b-4dff-d07a-ef39ac0edbe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "RFC = RandomForestClassifier(random_state=42)\n",
        "param_grid = {'n_estimators': [300,400,500],\n",
        "    'max_features': [1,0.5,0.3], 'max_samples':[1,0.5,0.3], 'bootstrap':[True,False]}\n",
        "clf = GridSearchCV(RFC, param_grid, scoring='f1',cv=10,)\n",
        "clf.fit(Updated_X_train, Y_train)\n",
        "\n",
        "RFC_best = clf.best_estimator_\n",
        "scores = cross_val_score(RFC, Updated_X_train, Y_train)\n",
        "scores_mean = round(scores.mean(),3)\n",
        "scores_std = round(scores.std(),3)\n",
        "print('Best_estimator:', RFC_best)\n",
        "print('Best_score_results:', round(clf.best_score_,3))\n",
        "print('Mean value:', scores_mean)\n",
        "print('Standard Deviation:',scores_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best_estimator: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features=0.3,\n",
            "                       max_leaf_nodes=None, max_samples=0.5,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "Best_score_results: 0.785\n",
            "Mean value: 0.833\n",
            "Standard Deviation: 0.016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn7UXQFMvxEJ"
      },
      "source": [
        "Top 2: Support Vector Machine Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LjbtIZ6j92t",
        "outputId": "77c203f2-529e-4ae7-9053-89693f030e7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sklearn\n",
        "svc = sklearn.svm.SVC()\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#No need to assign kernel to 'rbf'. It is that by default.\n",
        "clfsvm = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
        "\n",
        "param_grid = { }\n",
        "clfsvm = GridSearchCV(clfsvm,param_grid, scoring='f1',cv=10,)\n",
        "clfsvm.fit(Updated_X_train, Y_train)\n",
        "\n",
        "SVM_best = clfsvm.best_estimator_\n",
        "\n",
        "scores = cross_val_score(clfsvm, Updated_X_train, Y_train)\n",
        "scores_mean = round(scores.mean(),3)\n",
        "scores_std = round(scores.std(),3)\n",
        "print('Best_estimator:', SVM_best)\n",
        "print('Best_score_results:', round(clfsvm.best_score_,3))\n",
        "print('Mean value:', scores_mean)\n",
        "print('Standard Deviation:',scores_std)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best_estimator: Pipeline(memory=None,\n",
            "         steps=[('standardscaler',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('svc',\n",
            "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
            "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
            "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                     probability=False, random_state=42, shrinking=True,\n",
            "                     tol=0.001, verbose=False))],\n",
            "         verbose=False)\n",
            "Best_score_results: 0.749\n",
            "Mean value: 0.749\n",
            "Standard Deviation: 0.028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9gptUL3v709"
      },
      "source": [
        "Top 3: ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFyqVf8Xj-Wc"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "etc = ExtraTreesClassifier(random_state=42)\n",
        "param_grid = {'n_estimators': [300,400,500],\n",
        "    'max_features': [1,0.5,0.3], 'max_samples':[1,0.5,0.3], 'bootstrap':[True,False]}\n",
        "etc = GridSearchCV(etc, param_grid, scoring='f1',cv=10,)\n",
        "etc.fit(Updated_X_train, Y_train)\n",
        "\n",
        "scores = cross_val_score(etc, Updated_X_train, Y_train)\n",
        "\n",
        "ETC_best = etc.best_estimator_\n",
        "scores_mean = scores.mean()\n",
        "scores_std = scores.std()\n",
        "print('Best_estimator:', etc.best_estimator_)\n",
        "print('Best_score_results:', etc.best_score_)\n",
        "print('Mean value:', scores_mean)\n",
        "print('Standard Deviation:',scores_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk1WkMIS_68R"
      },
      "source": [
        "### 5) h) For the top 3 best performing classifiers, plot the learning curve chart. You can benefit from the following page for the plot:\n",
        "\n",
        "Kaggl Titanic: A Machine Learning from Disaster | Modelling Part 2: \n",
        "https://www.codementor.io/@innat_2k14/kaggl-titanic-a-machine-learning-from-disaster-modelling-part-2-10gfjtm0p3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOY9qXiwV7C8"
      },
      "source": [
        "RandomForestClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBhm61ijIO3",
        "outputId": "16559687-d393-454c-ebc2-ad96152f903e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.datasets import load_digits \n",
        "from sklearn.model_selection import learning_curve \n",
        "\n",
        " \n",
        "\n",
        "# Obtain scores from learning curve function \n",
        "# cv is the number of folds while performing Cross Validation \n",
        "sizes, training_scores, testing_scores = learning_curve(clf.best_estimator_, Updated_X_train, Y_train, cv=10, train_sizes=np.linspace(0.01, 1.0, 50)) \n",
        "\n",
        "# Mean and Standard Deviation of training scores \n",
        "mean_training = np.mean(training_scores, axis=1) \n",
        "Standard_Deviation_training = np.std(training_scores, axis=1) \n",
        "\n",
        "# Mean and Standard Deviation of testing scores \n",
        "mean_testing = np.mean(testing_scores, axis=1) \n",
        "Standard_Deviation_testing = np.std(testing_scores, axis=1) \n",
        "\n",
        "# dotted blue line is for training scores and green line is for cross-validation score \n",
        "plt.plot(sizes, mean_training, '--', color=\"b\", label=\"Training score\") \n",
        "plt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n",
        "\n",
        "# Drawing plot \n",
        "plt.title(\"LEARNING CURVE FOR RFC Classifier\") \n",
        "plt.xlabel(\"Training\"), plt.ylabel(\"Score\"), plt.legend(loc=\"best\") \n",
        "plt.tight_layout() \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEed27XGkNpk"
      },
      "source": [
        "Support Vector Machine (kernel='rbf' parameter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAnIxi6IWbZT",
        "outputId": "a2fd4a38-e553-4b4e-e7de-7e9fda6420bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Importing Required Libraries and Modules \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.datasets import load_digits \n",
        "from sklearn.model_selection import learning_curve \n",
        "\n",
        " \n",
        "\n",
        "# Obtain scores from learning curve function \n",
        "# cv is the number of folds while performing Cross Validation \n",
        "sizes, training_scores, testing_scores = learning_curve(clfsvm.best_estimator_, Updated_X_train, Y_train, cv=10, train_sizes=np.linspace(0.01, 1.0, 50)) \n",
        "\n",
        "# Mean and Standard Deviation of training scores \n",
        "mean_training = np.mean(training_scores, axis=1) \n",
        "Standard_Deviation_training = np.std(training_scores, axis=1) \n",
        "\n",
        "# Mean and Standard Deviation of testing scores \n",
        "mean_testing = np.mean(testing_scores, axis=1) \n",
        "Standard_Deviation_testing = np.std(testing_scores, axis=1) \n",
        "\n",
        "# dotted blue line is for training scores and green line is for cross-validation score \n",
        "plt.plot(sizes, mean_training, '--', color=\"b\", label=\"Training score\") \n",
        "plt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n",
        "\n",
        "# Drawing plot \n",
        "plt.title(\"LEARNING CURVE FOR SVM Classifier\") \n",
        "plt.xlabel(\"Training\"), plt.ylabel(\"Score\"), plt.legend(loc=\"best\") \n",
        "plt.tight_layout() \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbkZuwpGHtG9"
      },
      "source": [
        "ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTHpkzAHxyi",
        "outputId": "018f3172-9d50-4e6e-d9cc-78c3fdf8c336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "#Importing Required Libraries and Modules \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.datasets import load_digits \n",
        "from sklearn.model_selection import learning_curve \n",
        "\n",
        " \n",
        "\n",
        "# Obtain scores from learning curve function \n",
        "# cv is the number of folds while performing Cross Validation \n",
        "sizes, training_scores, testing_scores = learning_curve(etc.best_estimator_, Updated_X_train, Y_train, cv=10, train_sizes=np.linspace(0.01, 1.0, 50)) \n",
        "\n",
        "# Mean and Standard Deviation of training scores \n",
        "mean_training = np.mean(training_scores, axis=1) \n",
        "Standard_Deviation_training = np.std(training_scores, axis=1) \n",
        "\n",
        "# Mean and Standard Deviation of testing scores \n",
        "mean_testing = np.mean(testing_scores, axis=1) \n",
        "Standard_Deviation_testing = np.std(testing_scores, axis=1) \n",
        "\n",
        "# dotted blue line is for training scores and green line is for cross-validation score \n",
        "plt.plot(sizes, mean_training, '--', color=\"b\", label=\"Training score\") \n",
        "plt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n",
        "\n",
        "# Drawing plot \n",
        "plt.title(\"LEARNING CURVE FOR ETC Classifier\") \n",
        "plt.xlabel(\"Training\"), plt.ylabel(\"Score\"), plt.legend(loc=\"best\") \n",
        "plt.tight_layout() \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-434d89a10f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Obtain scores from learning curve function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# cv is the number of folds while performing Cross Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpdated_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Mean and Standard Deviation of training scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PybDCeKHdhgu"
      },
      "source": [
        "### 5) i) Use VotingClassifier of sklearn to create an ensemble learner that utilizes the top 3 estimators you found above. Set the voting parameter to 'soft'. Use cross_val_score to calculate its score and print out its mean and std values. The following page might be useful:\n",
        "\n",
        "Kaggl Titanic: A Machine Learning from Disaster | Modelling Part 2: \n",
        "https://www.codementor.io/@innat_2k14/kaggl-titanic-a-machine-learning-from-disaster-modelling-part-2-10gfjtm0p3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXg94uYl-Nt"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "VotingPredictor = VotingClassifier(estimators =\n",
        "                           [('rfc', RFC_best), \n",
        "                            ('svm', SVM_best),\n",
        "                            ('etc', ETC_best)],\n",
        "                           voting='soft')\n",
        "\n",
        "\n",
        "VotingPredictor = VotingPredictor.fit(Updated_X_train, Y_train)\n",
        "\n",
        "scores = cross_val_score(VotingPredictor, Updated_X_train, Y_train, cv = K_fold,\n",
        "                        scoring = 'accuracy')\n",
        "\n",
        "print(scores)\n",
        "print(round(np.mean(scores)*100, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX8xGOfLe359"
      },
      "source": [
        "### 5) j) Use the VotingClassifier you created above to predict 'Survived' for the X_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g7sP3bxmBFU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3EIbxWIgItM"
      },
      "source": [
        "### 5) k) Prepare a csv file to submit to kaggle.com. Submit it and then put your results here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTn961j5mDpz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbvpCx-g18Z"
      },
      "source": [
        "### 5) l) Think of what you can do extra to improve your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvKKMWtKhG8-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aGij_8ohKLr"
      },
      "source": [
        "### 5) m) (Bonus) Apply those idea(s) and then make another submission. Put your results here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mzvznaDmHHw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXuQXJr3mGRq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdH_8ldxDBRG"
      },
      "source": [
        "## 6) Run all of your code and get your output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSux2AVKHth3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHc95F7CGupC"
      },
      "source": [
        "## 7) Print the latest status of your notebook to a pdf file \n",
        "- The pdf file must include the link of your jupyter notebook page (see step 2 above)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcLDxwqrG3Zx"
      },
      "source": [
        "## 8) Submit the PDF file on Canvas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59LSrX0TSaDK",
        "outputId": "04751fd3-faf8-47e6-9439-f5baf5269cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('Project_Titanic_Part_2_AlexisDowning.ipynb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘colab_pdf.py’ already there; not retrieving.\n",
            "\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 2s (133 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "texlive-fonts-recommended is already the newest version (2017.20180305-1).\n",
            "texlive-generic-recommended is already the newest version (2017.20180305-1).\n",
            "texlive-xetex is already the newest version (2017.20180305-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/Project_Titanic_Part_2_AlexisDowning.ipynb to pdf\n",
            "[NbConvertApp] Support files will be in Project_Titanic_Part_2_AlexisDowning_files/\n",
            "[NbConvertApp] Making directory ./Project_Titanic_Part_2_AlexisDowning_files\n",
            "[NbConvertApp] Making directory ./Project_Titanic_Part_2_AlexisDowning_files\n",
            "[NbConvertApp] Writing 179338 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: [u'bibtex', u'./notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 163931 bytes to /content/drive/My Drive/Project_Titanic_Part_2_AlexisDowning.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cba79e90-56ac-4095-b93e-a7a9e7ded540\", \"Project_Titanic_Part_2_AlexisDowning.pdf\", 163931)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File ready to be Downloaded and Saved to Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}